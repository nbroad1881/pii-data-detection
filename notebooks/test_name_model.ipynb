{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "dotenv_path = Path(\"../../.env\")\n",
    "if dotenv_path.exists():\n",
    "    print(\"Loaded .env file!\")\n",
    "    load_dotenv(str(dotenv_path))\n",
    "\n",
    "\n",
    "data = json.load(open(Path(os.environ[\"PROJECT_HOME_DIR\"]) / \"data/train.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Nathalie', 'Sylla', 'Nathalie', 'Sylla', 'Nathalie', 'Sylla'],\n",
       " ['Diego', 'Estrada', 'Diego', 'Estrada'],\n",
       " ['Gilberto', 'Gamboa'],\n",
       " ['Sindy', 'Samaca'],\n",
       " ['Nadine', 'Born'],\n",
       " ['Eladio', 'Amaya'],\n",
       " ['Silvia', 'Villalobos'],\n",
       " ['Sakir', 'Ahmad'],\n",
       " ['Francisco', 'Ferreira'],\n",
       " ['Stefano', 'Lovato'],\n",
       " ['Al'],\n",
       " ['Pepa', 'Medrano'],\n",
       " ['Deiby'],\n",
       " ['Fareed', 'Ponce'],\n",
       " ['Claudia', 'Sarria'],\n",
       " ['Rajinder', 'Santos'],\n",
       " ['Maud', 'Dias', 'Maud', 'Dias', 'Maud', 'Dias', 'Maud', 'Dias'],\n",
       " [],\n",
       " ['Zia'],\n",
       " ['Davide', 'Carletti'],\n",
       " ['Karan', 'Patel'],\n",
       " ['Milton', 'Desai'],\n",
       " ['Luis', 'Ramadan'],\n",
       " ['Cesar', 'Rivera'],\n",
       " ['Dharmendra', 'Asiri', 'Dharmendra', 'Asiri'],\n",
       " ['Daniel'],\n",
       " ['Suhag', 'Shah'],\n",
       " ['Eina', 'Nazim'],\n",
       " ['Mauro', 'Pacheco'],\n",
       " ['Gabriel',\n",
       "  'Bravo',\n",
       "  'Hlengiwe',\n",
       "  'Swetha',\n",
       "  'Tino',\n",
       "  'Swetha',\n",
       "  'Tino',\n",
       "  'Lopez',\n",
       "  'Swetha',\n",
       "  'Swetha',\n",
       "  'Alex',\n",
       "  'Swetha',\n",
       "  'Alex',\n",
       "  'Bravo',\n",
       "  'Tino',\n",
       "  'Lopez',\n",
       "  'Hlengiwe'],\n",
       " ['Mohd', 'Asim'],\n",
       " ['Wilson', 'Syafinaz', 'Wilson', 'Syafinaz'],\n",
       " ['Madina', 'Eno'],\n",
       " ['Amparo'],\n",
       " ['Edgar', 'Lara'],\n",
       " ['Ahmed', 'Saeed', 'Ahmed', 'Saeed', 'Ahmed', 'Saeed'],\n",
       " ['Joao', 'Courtois'],\n",
       " ['Manuel', 'Vazquez'],\n",
       " ['Mlungisi', 'Msibi'],\n",
       " ['Fatima',\n",
       "  'Molina',\n",
       "  'Fatima',\n",
       "  'Fatima',\n",
       "  'Fatima',\n",
       "  'Fatima',\n",
       "  'Fatima',\n",
       "  'Fatima',\n",
       "  'Fatima'],\n",
       " ['Narayan', 'Majid'],\n",
       " ['Jose', 'Torres'],\n",
       " ['Florian', 'Richter'],\n",
       " ['David', 'Gonzalez'],\n",
       " ['Simon', 'Nkabinde'],\n",
       " ['Asim', 'Sunar'],\n",
       " ['Vicki', 'Mahi', 'Vicki', 'Mahi'],\n",
       " ['Olivier', 'Collet', 'Olivier', 'Collet'],\n",
       " ['Abul', 'Polidori'],\n",
       " [],\n",
       " ['Sjoerd', 'Van', 'Der', 'Wal'],\n",
       " ['Medo', 'Uddin', 'Medo', 'Uddin'],\n",
       " ['Diadie', 'Singh'],\n",
       " ['Sandra', 'Gonzales'],\n",
       " ['Valdecir', 'Pereira'],\n",
       " ['Saeed', 'Afridi'],\n",
       " ['Yvonne', 'Schmidt'],\n",
       " ['Aline', 'Lima', 'Aline', 'Lima'],\n",
       " ['Priyanka', 'Khan'],\n",
       " ['Frutos', 'Orellana'],\n",
       " ['Jacqueline', 'Stuurman'],\n",
       " ['Andreia', 'Rodrigues'],\n",
       " ['Diana', 'Alfonso'],\n",
       " ['Imtiyaz'],\n",
       " ['Mario', 'Markovic'],\n",
       " ['Shirley', 'Medina'],\n",
       " ['Craig', 'Gonzalez', 'Craig', 'Gonzalez'],\n",
       " ['Neha', 'Sharma'],\n",
       " ['Ilir', 'Ahmed', 'Ilir', 'Ahmed', 'Ilir', 'Ahmed'],\n",
       " ['Shailesh', 'Jain'],\n",
       " ['Waliur', 'Aslam'],\n",
       " ['Mike', 'Montenegro'],\n",
       " ['Muhammad', 'Seif'],\n",
       " ['Mohamed', 'Mahmod'],\n",
       " ['Ravneet', 'Williams'],\n",
       " ['Pushpalatha', 'Bisht'],\n",
       " ['Olga', 'Alvarez', 'Olga', 'Alvarez'],\n",
       " ['Maicol', 'Sanchez', 'Maicol', 'Sanchez'],\n",
       " ['Adri', 'Casal'],\n",
       " ['Asif', 'Khan'],\n",
       " ['Linda', 'Edwards'],\n",
       " [],\n",
       " ['Loredana', 'Abidin'],\n",
       " ['Adam',\n",
       "  'Filip',\n",
       "  'Saman',\n",
       "  'Mojica',\n",
       "  'Saman',\n",
       "  'Saman',\n",
       "  'Saman',\n",
       "  'Saman',\n",
       "  'Saman',\n",
       "  'Saman',\n",
       "  'Saman',\n",
       "  'Adam',\n",
       "  'Filip',\n",
       "  'Saman',\n",
       "  'Saman',\n",
       "  'Saman',\n",
       "  'Saman',\n",
       "  'Saman',\n",
       "  'Saman',\n",
       "  'Saman',\n",
       "  'Saman'],\n",
       " ['Sunny'],\n",
       " ['Susan', 'Pritchard'],\n",
       " ['Ruben', 'Soria'],\n",
       " ['Jaya', 'Madni'],\n",
       " ['Santosh', 'Kumar'],\n",
       " ['Bilal', 'Sajid', 'Bilal', 'Sajid', 'Bilal', 'Sajid'],\n",
       " ['Melvin', 'Lu'],\n",
       " ['Dieter', 'Berger'],\n",
       " ['Maicol', 'Toro'],\n",
       " ['John', 'Estrada'],\n",
       " ['James', 'Gray', 'James', 'Gray'],\n",
       " ['Md', 'Hamid'],\n",
       " ['Jorge', 'Bernardo'],\n",
       " ['Diana', 'Palacios', 'Diana', 'Palacios', 'Diana', 'Palacios'],\n",
       " ['Carolina', 'Finetti', 'Carolina', 'Gomez'],\n",
       " ['Ignacia', 'Hernandez'],\n",
       " ['Amal', 'Bhai'],\n",
       " ['Ahmed', 'Figo'],\n",
       " ['Guddu', 'Singh'],\n",
       " ['Ahmed', 'Salem', 'Ahmed', 'Salem'],\n",
       " ['Fabio', 'Sameh'],\n",
       " ['Ashley', 'Ashley', 'Ashley', 'Ashley', 'Ashley', 'Ashley'],\n",
       " ['Randy', 'Sanz'],\n",
       " ['Rodriguez'],\n",
       " ['Joe', 'Ferrara'],\n",
       " ['Suman', 'Salim'],\n",
       " ['Cynthia', 'Chatel'],\n",
       " ['Kaur', 'Rubio'],\n",
       " ['Karim', 'Elnazer'],\n",
       " ['Kamrul', 'Javed'],\n",
       " [],\n",
       " ['Ofelia', 'Ofelia'],\n",
       " ['Diana', 'Vazquez'],\n",
       " [],\n",
       " ['Muhammad', 'Shafiq'],\n",
       " ['Rhiannon',\n",
       "  'Karim',\n",
       "  'Rhiannon',\n",
       "  'Karim',\n",
       "  'Rhiannon',\n",
       "  'Karim',\n",
       "  'Rhiannon',\n",
       "  'Karim',\n",
       "  'Rhiannon',\n",
       "  'Karim'],\n",
       " ['Shivam', 'Giri'],\n",
       " ['Sara', 'Perez'],\n",
       " ['Fabian', 'Jones'],\n",
       " ['Diego', 'Claro'],\n",
       " ['Daniele', 'Saponara', 'Chabelo', 'Reyes'],\n",
       " ['Desiree', 'Mazza'],\n",
       " ['Antonio', 'Bellafiore'],\n",
       " [],\n",
       " ['Esraa', 'Han'],\n",
       " ['Bekim', 'Campanelli'],\n",
       " ['Blanca', 'Villa'],\n",
       " ['Mynor', 'Garcia', 'Lopez'],\n",
       " ['Hussain', 'Mohammed', 'Hussain', 'Mohammed'],\n",
       " ['Adelino', 'Carneiro'],\n",
       " ['Denis',\n",
       "  'Johnson',\n",
       "  'Katia',\n",
       "  'Johnson',\n",
       "  'Katia',\n",
       "  'Johnson',\n",
       "  'Denis',\n",
       "  'Johnson'],\n",
       " ['Jorge', 'Garrido'],\n",
       " ['Firoz', 'Khan', 'Pandey'],\n",
       " ['Fabiana', 'Braga'],\n",
       " ['Marcelo', 'Caroline'],\n",
       " ['Mohmad', 'Ali', 'Mohmad', 'Ali'],\n",
       " ['Jakeline', 'Lunardi'],\n",
       " ['Nurul', 'Ghani'],\n",
       " ['Francy', 'Ramos'],\n",
       " ['Sanam', 'Khan', 'Sanam', 'Khan'],\n",
       " ['Leonardo',\n",
       "  'Torres',\n",
       "  'Irina',\n",
       "  'Leonardo',\n",
       "  'Irina',\n",
       "  'Irina',\n",
       "  'Luca',\n",
       "  'Irina',\n",
       "  'Luca',\n",
       "  'Luca',\n",
       "  'Leonardo',\n",
       "  'Torres'],\n",
       " ['Joyce', 'Ka'],\n",
       " ['Uwe', 'Wegener'],\n",
       " ['Carmen', 'Perez'],\n",
       " ['Ganesh', 'Kumar', 'Ganesh', 'Kumar', 'Ganesh', 'Kumar'],\n",
       " ['Maria',\n",
       "  'Laitinen',\n",
       "  'Maria',\n",
       "  'Laitinen',\n",
       "  'Maria',\n",
       "  'Laitinen',\n",
       "  'Maria',\n",
       "  'Laitinen'],\n",
       " ['Juan', 'Flores'],\n",
       " ['Ismael', 'Garcia', 'Ismael', 'Garcia'],\n",
       " ['Blanca',\n",
       "  'Serrano',\n",
       "  'Blanca',\n",
       "  'Serrano',\n",
       "  'Blanca',\n",
       "  'Serrano',\n",
       "  'Blanca',\n",
       "  'Serrano'],\n",
       " ['Mohammed', 'Salah'],\n",
       " ['Tara', 'Limbu', 'Tara', 'Limbu', 'Tara', 'Limbu'],\n",
       " ['Pankaj', 'Sahu'],\n",
       " ['Robin', 'Duffy', 'Robin', 'Duffy'],\n",
       " ['Manuela', 'Lucas'],\n",
       " ['Javier', 'Castellanos'],\n",
       " ['Vero', 'Reyes'],\n",
       " ['Mary', 'Mohamed'],\n",
       " ['Aakash', 'Kumar', 'Aakash', 'Kumar', 'Aakash', 'Kumar', 'Aakash', 'Kumar'],\n",
       " ['Rosa', 'Perna', 'Leo', 'Ine'],\n",
       " ['Lidia', 'Palma'],\n",
       " ['Rehab', 'Mariam'],\n",
       " ['Ashley'],\n",
       " ['Magdy', 'Ruslan'],\n",
       " ['Anne', 'Marie', 'Sanquer', 'Anne', 'Marie', 'Sanquer'],\n",
       " ['Francesco', 'Rizzi'],\n",
       " ['Alvaro', 'Moreno'],\n",
       " ['Sarah', 'Gomez'],\n",
       " ['Mohamed', 'Smith', 'Mohamed', 'Smith'],\n",
       " ['Bryan', 'Sanchez'],\n",
       " ['Zakir'],\n",
       " ['Jean', 'Pierre', 'Jouanne'],\n",
       " ['Diogo', 'Costa'],\n",
       " ['Fernando', 'Soares'],\n",
       " ['Rosa', 'Jaque'],\n",
       " ['Mauro', 'Carella', 'Mauro', 'Carella'],\n",
       " ['Helena', 'Cavaco'],\n",
       " ['Mohammed', 'Mohammed', 'Mohammed', 'Mohammed'],\n",
       " ['Ajay', 'Preet'],\n",
       " ['Michael', 'Kl'],\n",
       " ['Tyler', 'Okey', 'Sin', 'Nazri', 'Ivan', 'Marta', 'Liz', 'Okey'],\n",
       " ['Keith', 'Khan'],\n",
       " [],\n",
       " ['Manuel', 'Medina'],\n",
       " ['Zakaria', 'Hassan', 'Zakaria', 'Hassan'],\n",
       " ['Syed', 'Aziz', 'Syed', 'Aziz'],\n",
       " ['Carolina', 'Romero'],\n",
       " ['Ahmed', 'Samuel'],\n",
       " ['Eija', 'Kinnunen', 'Eija', 'Kinnunen'],\n",
       " ['Edgar', 'Rojas'],\n",
       " ['Michael', 'Neubert'],\n",
       " [],\n",
       " ['Mithilesh', 'Gupta'],\n",
       " ['Yunier', 'Leung'],\n",
       " ['Aman', 'Baloch'],\n",
       " ['Virat', 'Patel'],\n",
       " ['Gabriel', 'Lara', 'Gabriel', 'Lara'],\n",
       " ['Bappa', 'Singh'],\n",
       " ['Jessie', 'Belal', 'Jessie', 'Belal'],\n",
       " ['Cedric', 'Sanchez'],\n",
       " ['Annie', 'Annie'],\n",
       " ['Isabel', 'Yomna'],\n",
       " ['Francisco', 'Parra'],\n",
       " ['Md', 'Rashid'],\n",
       " ['Vincenzo', 'Vincenzo', 'Reshma', 'Marco'],\n",
       " ['Md', 'Shamim'],\n",
       " ['Abdul', 'Vassallo'],\n",
       " ['Willian', 'Sanches', 'Willian', 'Sanches', 'Willian', 'Sanches'],\n",
       " ['Daniele', 'Prezioso'],\n",
       " ['Angela'],\n",
       " ['Qais'],\n",
       " ['Martin', 'Soares'],\n",
       " ['Busisiwe', 'Msimanga'],\n",
       " ['Mohammad', 'Azwan'],\n",
       " ['Joy', 'Cooper'],\n",
       " ['Luis', 'Vasquez'],\n",
       " ['Eslam', 'Abo', 'Fatma'],\n",
       " ['Felipe', 'Moreno'],\n",
       " ['Byron', 'Morton'],\n",
       " ['Oscar', 'Cruz'],\n",
       " ['Teresa'],\n",
       " ['Ioanna', 'Singh'],\n",
       " ['Jens', 'Hoffmann'],\n",
       " ['Jan', 'Peters'],\n",
       " ['Maribel', 'Rodriguez'],\n",
       " ['Rita', 'Francois', 'Rita', 'Francois'],\n",
       " ['Juan', 'Jose', 'Diaz'],\n",
       " ['Maria', 'Panagiotopoulou', 'Maria', 'Panagiotopoulou'],\n",
       " ['Nizam', 'Ahmed', 'Sana', 'Ahmed', 'Asmaa', 'Ahmed'],\n",
       " ['Fatin', 'Tam'],\n",
       " ['Edjanio', 'Sousa'],\n",
       " ['Norma', 'Valenzuela', 'Norma', 'Valenzuela'],\n",
       " ['Michelle', 'Cara', 'Michelle', 'Cara'],\n",
       " ['Mdjakir', 'Puerta'],\n",
       " ['David', 'William', 'Sajid', 'Khan', 'Sajid', 'Khan'],\n",
       " ['Ernesto', 'Young'],\n",
       " ['Yasmin', 'Moustafa'],\n",
       " ['Ganpat', 'Rathod', 'Ganpat', 'Rathod'],\n",
       " ['Steven', 'Richards'],\n",
       " ['Guadalupe', 'Khan'],\n",
       " ['Carlos', 'Pablo'],\n",
       " ['Nor', 'Fitri'],\n",
       " ['Maria', 'Garcia'],\n",
       " [],\n",
       " [],\n",
       " ['Kashi', 'Papa'],\n",
       " ['Shareef', 'Ahmed'],\n",
       " ['Perle', 'Kamdem', 'Perle', 'Kamdem'],\n",
       " ['Priyanka', 'Ansari'],\n",
       " ['Cherry', 'Dantas'],\n",
       " ['Isabelle', 'Laurent'],\n",
       " ['Luis', 'Sierra', 'Luis', 'Sierra'],\n",
       " ['Zohaib',\n",
       "  'Ashraf',\n",
       "  'Matheus',\n",
       "  'Kumari',\n",
       "  'Matheus',\n",
       "  'Kumari',\n",
       "  'Matheus',\n",
       "  'Kumari',\n",
       "  'Matheus',\n",
       "  'Kumari',\n",
       "  'Matheus',\n",
       "  'Kumari',\n",
       "  'Matheus',\n",
       "  'Kumari',\n",
       "  'Matheus'],\n",
       " ['Shafi', 'Hartley'],\n",
       " ['Al', 'Kain'],\n",
       " ['Mario', 'Pedrini'],\n",
       " ['Vipan', 'Rashmi'],\n",
       " ['Raxa', 'Kumari'],\n",
       " ['Nitish', 'Kumar'],\n",
       " ['Dla', 'Xalid'],\n",
       " ['Luna', 'Arias'],\n",
       " ['Alex', 'Perez', 'Alex', 'Perez'],\n",
       " ['Arath', 'Sanchez'],\n",
       " ['Sarai', 'Diaz'],\n",
       " ['Jesus', 'Juarez'],\n",
       " ['Enzo', 'Richards', 'Enzo', 'Richards'],\n",
       " ['Rosa', 'Perez'],\n",
       " ['Dawn', 'James', 'Dawn', 'James', 'Dawn', 'James'],\n",
       " ['Chiara', 'Watson'],\n",
       " ['Gonzalo', 'Rodriguez'],\n",
       " ['Guilherme', 'Oliveira'],\n",
       " ['Edith', 'Orjuela'],\n",
       " ['Daniel', 'Chen'],\n",
       " ['Alexandra', 'Beyer'],\n",
       " ['Jose', 'Lopez'],\n",
       " ['Mustafa', 'Majid'],\n",
       " ['Karla', 'Hannan'],\n",
       " ['Francesco', 'Sanchez'],\n",
       " ['Raffaella', 'Perillo'],\n",
       " ['Chris', 'Humphries'],\n",
       " ['Moustapha', 'Santi'],\n",
       " ['Karina', 'Starks'],\n",
       " ['Mahmoud', 'Shaker'],\n",
       " ['Ratna', 'Kumari'],\n",
       " ['Lourdes', 'Gordon'],\n",
       " ['Jose', 'Garcia', 'Jose', 'Garcia'],\n",
       " ['Vijay',\n",
       "  'Shende',\n",
       "  'Vijay',\n",
       "  'Shende',\n",
       "  'Vijay',\n",
       "  'Shende',\n",
       "  'Emanuela',\n",
       "  'Emanuela',\n",
       "  'Vijay',\n",
       "  'Shende',\n",
       "  'Emanuela',\n",
       "  'Vijay',\n",
       "  'Shende',\n",
       "  'Charlotte',\n",
       "  'Molteni'],\n",
       " ['Amit', 'Sharma'],\n",
       " ['Salman', 'Kumar'],\n",
       " ['Castillo', 'Marie'],\n",
       " ['Talaat', 'Mohmmed'],\n",
       " ['Chris', 'Martinez'],\n",
       " ['Sagar', 'Ram'],\n",
       " ['Philippe', 'Elle'],\n",
       " ['Saly'],\n",
       " ['Jose', 'Gil'],\n",
       " ['Ndumiso', 'Khan'],\n",
       " [],\n",
       " ['Natalya', 'Kotov'],\n",
       " ['Abdul', 'Rohim', 'Abdul', 'Rohim'],\n",
       " ['Pietro', 'Gabrielli'],\n",
       " ['Kara', 'Deniz'],\n",
       " ['Mohamed', 'Kamal', 'Mohamed', 'Kamal'],\n",
       " ['Saadiah', 'Jie'],\n",
       " ['Giuseppe', 'Longo', 'Giuseppe', 'Longo'],\n",
       " ['Dharmendra', 'Dharmendra', 'Dharmendra', 'Dharmendra'],\n",
       " ['Federica', 'Federica'],\n",
       " ['Jo', 'Kelly'],\n",
       " ['Ivica', 'Marija'],\n",
       " ['Yaser', 'Mostafa'],\n",
       " ['May', 'Sutton'],\n",
       " ['Neia', 'Rodrigues'],\n",
       " ['Donya', 'Donya'],\n",
       " ['Sam', 'Chan', 'Karen'],\n",
       " ['Cristina', 'Valerio', 'Cristina', 'Valerio'],\n",
       " ['Sara', 'Garcia'],\n",
       " ['Leonardo', 'Giles'],\n",
       " [],\n",
       " ['Mohamad'],\n",
       " ['Margarita', 'Gould'],\n",
       " ['Yareli', 'Thomas'],\n",
       " ['Karla'],\n",
       " ['Uriel', 'Romero'],\n",
       " [],\n",
       " ['Sarah', 'Calixto', 'Sarah', 'Calixto'],\n",
       " ['Enrico', 'Laterza'],\n",
       " ['Yessica', 'Lopes'],\n",
       " ['Lerato', 'Salem'],\n",
       " ['Silvia'],\n",
       " ['Abdul', 'Nasar'],\n",
       " ['Siew', 'Santamaria'],\n",
       " ['Julia', 'Bock'],\n",
       " ['Angelo', 'Martello'],\n",
       " ['Martina', 'Chong'],\n",
       " ['Hari', 'Sharma'],\n",
       " ['Thai', 'Tamang'],\n",
       " ['Victoria', 'Horton'],\n",
       " ['Mahammad', 'Khan'],\n",
       " ['Stephanie', 'Johnstone'],\n",
       " ['Christian'],\n",
       " ['Khairul', 'Rahman'],\n",
       " ['Sagar', 'Sanchez'],\n",
       " ['Alexandra', 'Serafini'],\n",
       " ['Phillip', 'Santillan'],\n",
       " ['Gino', 'Schiavo'],\n",
       " [],\n",
       " ['Alison'],\n",
       " ['Jana', 'Telfah', 'Jana', 'Telfah', 'Jana', 'Telfah'],\n",
       " [],\n",
       " ['Andres', 'Castro', 'Andres', 'Castro'],\n",
       " ['Juan', 'Chavez'],\n",
       " ['Carlos', 'Hernandez'],\n",
       " ['Johan', 'Caro', 'Johan', 'Caro'],\n",
       " ['Priya', 'Jeet', 'Priya', 'Jeet'],\n",
       " ['Ashley', 'Arias'],\n",
       " ['Hanan', 'Hassan'],\n",
       " ['Irfan', 'Khan', 'Irfan', 'Khan'],\n",
       " ['Waseem', 'Hamad', 'Waseem', 'Hamad', 'Waseem', 'Hamad'],\n",
       " ['Rania', 'Mohammed'],\n",
       " ['Juan', 'Velasquez'],\n",
       " [],\n",
       " ['Hiroshi', 'Tamura'],\n",
       " ['Jose', 'Martinez'],\n",
       " ['Imran', 'Singh', 'Shokat', 'Shokat'],\n",
       " ['Surya', 'Mohamad'],\n",
       " ['Nathan', 'Kumar'],\n",
       " ['Tiago', 'Borges'],\n",
       " ['Yuly', 'Ceballos'],\n",
       " ['Indhumathi', 'Shaikh', 'Indhumathi', 'Shaikh', 'Indhumathi', 'Shaikh'],\n",
       " ['Danielle', 'West'],\n",
       " ['Vinod', 'Baker'],\n",
       " ['Ajay', 'Vishwkarma', 'Zahida', 'Zahida', 'Zahida', 'Zahida', 'Zahida'],\n",
       " ['Luca', 'Luca'],\n",
       " ['Luka', 'Stanic', 'Luka', 'Stanic'],\n",
       " ['Anil', 'Dubey', 'Anil', 'Dubey', 'Anil', 'Dubey'],\n",
       " ['Karen', 'Gonzalez'],\n",
       " ['Mario', 'Lopez'],\n",
       " ['Cicero', 'Carlos'],\n",
       " ['John', 'Yates'],\n",
       " ['Mauro', 'Zizza'],\n",
       " ['Melissa', 'Martinez'],\n",
       " ['Karina', 'Duque'],\n",
       " ['Sonia', 'Salinas'],\n",
       " ['Akhilesh', 'Kumar'],\n",
       " ['Raffaele', 'Passalacqua'],\n",
       " ['Ahmad',\n",
       "  'Kumar',\n",
       "  'Ahmad',\n",
       "  'Ahmad',\n",
       "  'Jose',\n",
       "  'Kumar',\n",
       "  'Jose',\n",
       "  'Jose',\n",
       "  'Jose',\n",
       "  'Jose',\n",
       "  'Jose',\n",
       "  'Jose',\n",
       "  'Jose',\n",
       "  'Jose',\n",
       "  'Jose',\n",
       "  'Jose',\n",
       "  'Jose',\n",
       "  'Jose'],\n",
       " ['Lucas', 'Medina', 'Lucas', 'Medina'],\n",
       " ['Jennifer', 'Medina'],\n",
       " ['Katie', 'Wakefield'],\n",
       " [],\n",
       " ['Antonio', 'Coppola'],\n",
       " ['Gurwinder', 'Singh'],\n",
       " ['Hennie', 'Dijkstra'],\n",
       " ['Cristino', 'Ramirez'],\n",
       " ['Amritpal'],\n",
       " ['Roberta', 'Corona'],\n",
       " ['Madison', 'Tate'],\n",
       " ['Mohinder', 'Kumar'],\n",
       " ['Roberto', 'Pink'],\n",
       " ['Shujon', 'Rohman'],\n",
       " ['Gonzalo', 'Wong'],\n",
       " ['Anna', 'Russo', 'Anna', 'Russo', 'Anna', 'Russo'],\n",
       " ['Claudio', 'Said', 'Claudio', 'Said'],\n",
       " ['Camilo', 'Lopez'],\n",
       " ['Abdo', 'Cortes', 'Abdo', 'Cortes'],\n",
       " ['Charlotte', 'Jones'],\n",
       " ['Habibu', 'George'],\n",
       " ['Lucas', 'Moreira'],\n",
       " ['Linda', 'Moore', 'Linda', 'Moore', 'Linda', 'Moore'],\n",
       " ['Ifeoma', 'Kings', 'Ifeoma', 'Kings'],\n",
       " ['Shubham', 'Shubham'],\n",
       " [],\n",
       " ['Patrick'],\n",
       " ['Angelik'],\n",
       " ['Pablo', 'Romero'],\n",
       " ['Giuseppe', 'Alberti'],\n",
       " ['Regina', 'Parker', 'Regina', 'Parker'],\n",
       " ['Isabel', 'Pardal'],\n",
       " ['Samar', 'Mohamed'],\n",
       " ['Diego', 'Campo'],\n",
       " ['Jhonatan', 'De', 'Oliveira'],\n",
       " ['Eman', 'Rahaman'],\n",
       " ['Jyoti', 'Ward'],\n",
       " ['Hoa', 'Wong'],\n",
       " ['Jamal', 'Wahab'],\n",
       " ['Zhe', 'Basmah', 'Zhe', 'Zhe', 'Basmah'],\n",
       " ['Carlos', 'Pereira'],\n",
       " ['Wilma', 'Dekker', 'Wilma', 'Dekker'],\n",
       " ['Juan', 'Bakker'],\n",
       " ['Dharmendra', 'Shakya'],\n",
       " ['Alberto'],\n",
       " ['Manoj', 'Gowda'],\n",
       " ['Jose', 'Brown'],\n",
       " ['Steve', 'Hernandez'],\n",
       " ['Bruno', 'Milani'],\n",
       " ['Rashid', 'Kt'],\n",
       " ['Judith', 'Van', 'Den', 'Heuvel'],\n",
       " ['Md', 'Carrillo', 'Md', 'Carrillo'],\n",
       " ['Bas', 'Klaas'],\n",
       " ['Ori', 'Abrego'],\n",
       " ['Jaime', 'Smit'],\n",
       " ['Paula', 'Collins'],\n",
       " ['Aylin', 'Osorio', 'Aylin', 'Osorio'],\n",
       " ['Jimena'],\n",
       " [],\n",
       " ['Jose', 'Camacho'],\n",
       " ['Alberto', 'Campani', 'Alberto', 'Campani'],\n",
       " ['Julian', 'Ramirez'],\n",
       " ['Yogi', 'Yates'],\n",
       " ['Luis', 'Hernandez', 'Luis', 'Hernandez'],\n",
       " ['Abbas', 'Hernandez'],\n",
       " ['Elizabeth', 'Pedraza'],\n",
       " ['Miguel', 'Herrera'],\n",
       " ['Alma', 'Munoz'],\n",
       " ['Alejandra', 'Padilla', 'Alejandra', 'Padilla', 'Alejandra', 'Padilla'],\n",
       " ['Jose', 'Jackson', 'Jose', 'Jackson'],\n",
       " ['Joe', 'Hernandez'],\n",
       " ['Sharan', 'Chauhan'],\n",
       " ['Farjana', 'Iqbal'],\n",
       " ['Francesco'],\n",
       " ['Lalisa', 'Cruz'],\n",
       " ['Amira', 'Ali'],\n",
       " ['Om', 'Ahmed', 'Teto'],\n",
       " ['Jonathan', 'Vieira'],\n",
       " ['Pong', 'Ng'],\n",
       " ['Daniela'],\n",
       " ['Miguel', 'Caceres'],\n",
       " ['Sergio', 'Camilo'],\n",
       " [],\n",
       " ['Abdul', 'Khan'],\n",
       " ['Luis',\n",
       "  'Gonzales',\n",
       "  'Luis',\n",
       "  'Gonzales',\n",
       "  'Luis',\n",
       "  'Gonzales',\n",
       "  'Luis',\n",
       "  'Gonzales',\n",
       "  'Daniel',\n",
       "  'Nowak'],\n",
       " ['Ahmed', 'Maprok'],\n",
       " ['Nani', 'Peroni'],\n",
       " ['Michele', 'Schmidt', 'Michele', 'Schmidt', 'Michele', 'Schmidt'],\n",
       " ['Leroy',\n",
       "  'Sullivan',\n",
       "  'Leroy',\n",
       "  'Leroy',\n",
       "  'Sullivan',\n",
       "  'Leroy',\n",
       "  'Sullivan',\n",
       "  'Leroy',\n",
       "  'Sullivan',\n",
       "  'Leroy',\n",
       "  'Sullivan',\n",
       "  'Leroy'],\n",
       " ['Hugo', 'Mcintyre'],\n",
       " ['Komal', 'Li'],\n",
       " ['Giorgia', 'Piccolo', 'Giorgia', 'Piccolo'],\n",
       " ['Monica', 'Carlos'],\n",
       " ['Luca', 'Ciccone'],\n",
       " ['Johnny', 'Bryant'],\n",
       " ['Paolo', 'Rossi'],\n",
       " ['Mickael', 'Richardson', 'Mickael', 'Richardson'],\n",
       " ['Tina', 'Peralta'],\n",
       " ['Rabi', 'Jain'],\n",
       " ['Lydia', 'Wati'],\n",
       " ['Frankie', 'Kwan'],\n",
       " ['Aaron', 'Cruz'],\n",
       " ['Muhammad', 'Leonardo'],\n",
       " ['Ahmed', 'Carlos', 'Ahmed', 'Carlos', 'Ahmed', 'Alaa', 'Ahmed', 'Alaa'],\n",
       " ['Sujeet', 'Ruiz'],\n",
       " ['Ravinder', 'Pal'],\n",
       " ['Kojo', 'Oteng'],\n",
       " ['Quentin', 'Paul', 'Ortega', 'Quentin'],\n",
       " ['Maria', 'Meier'],\n",
       " [],\n",
       " ['Caterina', 'Mauro'],\n",
       " ['Paola', 'Romano'],\n",
       " ['Shamsun', 'Fawzy'],\n",
       " ['Fernanda', 'Moreira'],\n",
       " [],\n",
       " ['Gary'],\n",
       " ['Sameh'],\n",
       " [],\n",
       " ['Filip'],\n",
       " ['Stephen', 'Stephen'],\n",
       " ['Tracy', 'Simmons', 'Tracy', 'Simmons'],\n",
       " ['Roberto', 'Hasan', 'Roberto', 'Hasan', 'Roberto', 'Hasan'],\n",
       " ['Martina', 'Mazzoleni', 'Martina', 'Mazzoleni'],\n",
       " ['Geovanny', 'Lopez'],\n",
       " ['Kenichi', 'Watanabe'],\n",
       " ['Mohammed', 'Isah', 'Mohammed', 'Isah'],\n",
       " ['Paul', 'Basha'],\n",
       " ['Feroz', 'Saiful', 'Feroz', 'Saiful'],\n",
       " ['Ronnie', 'Shahed'],\n",
       " ['Angela', 'Torres', 'Angela', 'Torres', 'Angela', 'Torres'],\n",
       " ['Uwe', 'Bas'],\n",
       " ['Laura', 'Johnson'],\n",
       " ['Giuseppe', 'Petrosillo', 'El', 'Petrosillo'],\n",
       " ['Janet', 'Galletti', 'Janet'],\n",
       " ['Monika', 'Wolf'],\n",
       " ['Ali', 'Zarei'],\n",
       " ['Ismael', 'Aguirre'],\n",
       " ['Iva', 'Juric', 'Iva', 'Juric'],\n",
       " ['Monika', 'Seifert', 'Monika', 'Seifert'],\n",
       " ['Edson', 'Barbosa'],\n",
       " ['Dai'],\n",
       " ['Fernanda', 'Dourado'],\n",
       " ['Agim', 'Krieger'],\n",
       " ['Barbara', 'Pedro'],\n",
       " ['Mohamed', 'Nada', 'Ahmed', 'Ahmed'],\n",
       " ['Ahmad', 'Suryadi'],\n",
       " [],\n",
       " ['Philippe', 'Quesnel'],\n",
       " ['Richard', 'Moseley'],\n",
       " ['Nweze', 'Stanley', 'Nweze', 'Stanley'],\n",
       " ['Adigun', 'Okoro'],\n",
       " ['Sergio', 'Dworak'],\n",
       " ['Maga', 'Ivanova'],\n",
       " ['Javier', 'Vega'],\n",
       " ['Daniel', 'Vazquez'],\n",
       " ['Tony', 'Flores', 'Tony', 'Flores'],\n",
       " ['Mauro', 'Iorio'],\n",
       " ['Jose', 'Santos'],\n",
       " ['Ana', 'Sofia', 'Rayo'],\n",
       " ['Luz', 'Marina', 'Mora'],\n",
       " ['Carla', 'Yadav'],\n",
       " ['Basavaraju', 'Aakash', 'Kumar'],\n",
       " ['Nazmi', 'Molano'],\n",
       " ['Oumar', 'Rocca'],\n",
       " ['Pawan', 'Subash'],\n",
       " ['Abdul', 'Kalu', 'Abdul', 'Kalu', 'Abdul', 'Kalu'],\n",
       " [],\n",
       " ['Diego'],\n",
       " ['Rosli'],\n",
       " ['Blanca', 'Becerra'],\n",
       " ['Jamshed'],\n",
       " ['Teresa',\n",
       "  'Naser',\n",
       "  'Naser',\n",
       "  'Naser',\n",
       "  'Teresa',\n",
       "  'Naser',\n",
       "  'Naser',\n",
       "  'Teresa',\n",
       "  'Naser',\n",
       "  'Teresa',\n",
       "  'Teresa',\n",
       "  'Teresa',\n",
       "  'Naser',\n",
       "  'Naser'],\n",
       " ['Mohamad', 'Afiq'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Nandan', 'Velasco', 'Nandan', 'Nandan', 'Nandan'],\n",
       " [],\n",
       " ['Cesar', 'Mahmood'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Marwa'],\n",
       " [],\n",
       " ['Asia', 'Ibrahim'],\n",
       " [],\n",
       " [],\n",
       " ['Bunga', 'Abbas'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Roberta', 'Roberta'],\n",
       " [],\n",
       " [],\n",
       " ['Sipho', 'Mofokeng'],\n",
       " [],\n",
       " ['Maria', 'Williams'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Guido', 'Ahmad'],\n",
       " ['Tatsuya', 'Watanabe'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Wellington', 'Silva'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Salma'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Monica', 'Garcia'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Chris', 'Hammond'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Arnaldo', 'Campos'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Naga', 'Raju'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Alessio', 'Putino'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Sanne', 'Aarts'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Melvin', 'Alfaro'],\n",
       " [],\n",
       " [],\n",
       " ['Felice'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Luz', 'Young'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Manuela', 'Manuela'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Youssef',\n",
       "  'Schneider',\n",
       "  'Youssef',\n",
       "  'Youssef',\n",
       "  'Youssef',\n",
       "  'Youssef',\n",
       "  'Youssef',\n",
       "  'Youssef'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Vetri', 'Faezah'],\n",
       " [],\n",
       " ['Khan', 'Krishnan'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Laxman', 'Patil'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Suliman', 'Ansari'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Md', 'Yadav', 'Md', 'Yadav', 'Md', 'Yadav'],\n",
       " [],\n",
       " ['Corinna', 'Bruns'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Denise', 'Evans'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Alessandra',\n",
       "  'Farrag',\n",
       "  'Alessandra',\n",
       "  'Farrag',\n",
       "  'Alessandra',\n",
       "  'Farrag',\n",
       "  'Alessandra',\n",
       "  'Farrag'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Vanessa', 'Sanchez', 'Vanessa', 'Sanchez'],\n",
       " ['Neha', 'Singh'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Christina', 'Bennett'],\n",
       " [],\n",
       " ['Sachin', 'Cordova'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Bankole', 'Ismail'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Luis', 'Leon'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Perla', 'Luna'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Cherie', 'Gray'],\n",
       " ['Prakash', 'Prakash', 'Prakash', 'Prakash'],\n",
       " ['Gabriele', 'Khan', 'Gabriele', 'Khan'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Mireya', 'Montes'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Menna', 'Menna', 'Menna'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Antonio', 'Hanson', 'Antonio', 'Hanson', 'Antonio', 'Hanson'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Greg', 'Parker'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Vincenzo', 'Mondal', 'Vincenzo', 'Vincenzo', 'Vincenzo'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Johana'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Rupesh', 'Kumar', 'Ahmad', 'Rupesh', 'Kumar', 'Ahmad'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Fabrizio',\n",
       "  'Fabrizio',\n",
       "  'Fabrizio',\n",
       "  'Fabrizio',\n",
       "  'Fabrizio',\n",
       "  'Fabrizio',\n",
       "  'Fabrizio',\n",
       "  'Fabrizio',\n",
       "  'Fabrizio',\n",
       "  'Fabrizio',\n",
       "  'Fabrizio',\n",
       "  'Fabrizio',\n",
       "  'Fabrizio',\n",
       "  'Fabrizio',\n",
       "  'Fabrizio',\n",
       "  'Fabrizio',\n",
       "  'Fabrizio'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Vijay', 'Thea'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Brenda', 'Johnson', 'Brenda', 'Garcia'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Anjali',\n",
       "  'Rajput',\n",
       "  'Lupe',\n",
       "  'King',\n",
       "  'Jose',\n",
       "  'Luis',\n",
       "  'Jose',\n",
       "  'Luis',\n",
       "  'David',\n",
       "  'Rubin'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Hector', 'Rodriguez'],\n",
       " [],\n",
       " ['Amparo', 'Pimienta', 'Amparo', 'Pimienta'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Stella',\n",
       "  'Junaid',\n",
       "  'Junaid',\n",
       "  'Stella',\n",
       "  'Junaid',\n",
       "  'Stella',\n",
       "  'Junaid',\n",
       "  'Stella',\n",
       "  'Junaid'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Maria', 'Arroyo'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Monica', 'Torres'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Liliana', 'Clark', 'Liliana', 'Liliana', 'Liliana', 'Liliana'],\n",
       " [],\n",
       " [],\n",
       " ['Jan', 'Miah'],\n",
       " [],\n",
       " ['Thulani', 'Abdullahi', 'Mahmud'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Alejandro', 'Jerez'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Ajayi', 'Azubuike'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Mayara', 'Costa'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Maria', 'Amin'],\n",
       " [],\n",
       " ['Stephanie', 'Gonzalez', 'Stephanie', 'Gonzalez'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ...]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_names = []\n",
    "\n",
    "for d in data:\n",
    "    actual_names.append([x for x,y in zip(d[\"tokens\"], d[\"labels\"]) if \"NAME_STUDENT\" in y])\n",
    "\n",
    "actual_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoTokenizer, Trainer, TrainingArguments, pipeline\n",
    "\n",
    "model_path = \"/drive2/kaggle/pii-dd/piidd/training/names/outputs/d3b_lr_3e-5/checkpoint-524\"\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_path, device_map=0)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfbe93df4a784210b29f915a91123edb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicholas/miniconda3/lib/python3.10/site-packages/transformers/pipelines/base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "from transformers import pipeline\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "import datasets\n",
    "\n",
    "dataset = Dataset.from_dict({\"text\": [d[\"full_text\"] for d in data]})\n",
    "\n",
    "names = []\n",
    "\n",
    "# for out in tqdm(pl(KeyDataset(dataset, \"text\"), batch_size=8)):\n",
    "#     names.append(out)\n",
    "\n",
    "for d in tqdm(dataset[:100][\"text\"]):\n",
    "    names.append(pl(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Design Thinking for innovation reflexion-Avril 2021-Nathalie Sylla\\n\\nChallenge & selection\\n\\nThe tool I use to help all stakeholders finding their way through the complexity of a project is the  mind map.\\n\\nWhat exactly is a mind map? According to the definition of Buzan T. and Buzan B. (1999, Dessine-moi  l'intelligence. Paris: Les Éditions d'Organisation.), the mind map (or heuristic diagram) is a graphic  representation technique that follows the natural functioning of the mind and allows the brain's  potential to be released. Cf Annex1\\n\\nThis tool has many advantages:\\n\\n•  It is accessible to all and does not require significant material investment and can be done  quickly\\n\\n•  It is scalable\\n\\n•  It allows categorization and linking of information\\n\\n•  It can be applied to any type of situation: notetaking, problem solving, analysis, creation of  new ideas\\n\\n•  It is suitable for all people and is easy to learn\\n\\n•  It is fun and encourages exchanges\\n\\n•  It makes visible the dimension of projects, opportunities, interconnections\\n\\n•  It synthesizes\\n\\n•  It makes the project understandable\\n\\n•  It allows you to explore ideas\\n\\nThe creation of a mind map starts with an idea/problem located at its center. This starting point  generates ideas/work areas, incremented around this center in a radial structure, which in turn is  completed with as many branches as new ideas.\\n\\nThis tool enables creativity and logic to be mobilized, it is a map of the thoughts.\\n\\nCreativity is enhanced because participants feel comfortable with the method.\\n\\nApplication & Insight\\n\\nI start the process of the mind map creation with the stakeholders standing around a large board  (white or paper board). In the center of the board, I write and highlight the topic to design.\\n\\nThrough a series of questions, I guide the stakeholders in modelling the mind map. I adapt the series  of questions according to the topic to be addressed. In the type of questions, we can use: who, what,  when, where, why, how, how much.\\n\\nThe use of the “why” is very interesting to understand the origin. By this way, the interviewed person  frees itself from paradigms and thus dares to propose new ideas / ways of functioning. I plan two  hours for a workshop.\\n\\nDesign Thinking for innovation reflexion-Avril 2021-Nathalie Sylla\\n\\nAfter modelling the mind map on paper, I propose to the participants a digital visualization of their  work with the addition of color codes, images and interconnections. This second workshop also lasts  two hours and allows the mind map to evolve. Once familiarized with it, the stakeholders discover  the power of the tool. Then, the second workshop brings out even more ideas and constructive  exchanges between the stakeholders. Around this new mind map, they have learned to work  together and want to make visible the untold ideas.\\n\\nI now present all the projects I manage in this type of format in order to ease rapid understanding for  decision-makers. These presentations are the core of my business models. The decision-makers are  thus able to identify the opportunities of the projects and can take quick decisions to validate them.  They find answers to their questions thank to a schematic representation.\\n\\nApproach\\n\\nWhat I find amazing with the facilitation of this type of workshop is the participants commitment for  the project. This tool helps to give meaning. The participants appropriate the story and want to keep  writing it. Then, they easily become actors or sponsors of the project. A trust relationship is built,  thus facilitating the implementation of related actions.\\n\\nDesign Thinking for innovation reflexion-Avril 2021-Nathalie Sylla\\n\\nAnnex 1: Mind Map Shared facilities project\\n\\n\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][\"full_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in names if len(x) > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, [], ['Claudia', 'Sarria'])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.choice(list(zip(range(len(names)), names, actual_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Mind Mapping (Module 3)\\n\\nChallenge\\n\\nIn the third part we use a tool called mind map that in principal means that you  have to put all the relevant information about a topic and this would help to  understand better the topic that is in the organizer. Also in this type of organizer  we can found a lot of kind of mind maps for example, in the classification of  them, the most important are Library mind maps for information organizing,  Presentation mind maps for presenting ideas and projects and Tunnel timeline  mind maps for organizing or making a project plan.\\n\\nSelection\\n\\nIt is a powerful graphic technique you can use to translate what's in  your mind into a visual picture. Since mind mapping works like the brain does it  allows you to organize and understand information faster and better. Then, in my  opinion I think that this tool is a very good option to take some decisions because  with this tool you can see the most relevant information and the main point about  a topic and I choose this tool because I think that is very useful in the industry  because it gives a better view about an item and in some time the people that use  this could found the problem with this incredible tool in my opinion.\\n\\nApplication\\n\\nWe can applied this tool in four main techniques or applications. First get  creative, gather Requirements, bridge silos, brainstorm and finally collaborate.  When we use a mind map it allows that Subject Matter Experts and/or their  audience make cross references and it turns easily function as an instrument for  collaboration during a kick-off meeting, in their we can included notes, links,  attachments, images and even connect multiple mind-maps within a single map,  making it a one stop-shop for collaboration. This tool is a visual representation  during a project kick-off meeting or the front end analysis phase.\\n\\nIn second instance the other application is that this tool is allow to assess prior  knowledge, give an overview, create power-notes and build engagement. A lot of  people use mind maps for example trainer to spark and facilitate discussions and  the participants get the ability to contribute to group discussions, and report back  with the help of a mind map. Adult learners bring a wealth of prior knowledge  into the classroom.\\n\\nOther application is when we use it for present, outline, summarize, consolidate  and storyboard. Mind maps can easily be turned into broad outlines of course  objectives, as a word or a power point format and also we can use for feedback.  Outlines provide a high-level overview which helps summarize and consolidate  information. A semi-detailed map is a great instrument for power-notes, as well  as a road map for an agenda.\\n\\nTo finish the last one way that we can applied is in a project management, that is  use to complete and comprehensive mind map can be used to delegate phases of  the project. Mapping also helps set up priorities, create deadlines, action items,  budgets, constraints and dependencies.\\n\\nInsight\\n\\nWith the use of this tool I could say that it brings me more knowledge and it also  in my opinion is a very good tool and when I was working with this tool my  work became more easily I can say because with this tool I have more organized  ideas and also the main thing about the topic of my project and if I want to say  more about the knowledge with this tool is great because you can use this for a  lot of things and activities.\\n\\nApproach\\n\\nIn the next time that I will use this tool something that I will change is that  maybe I will have only the main information for my study because in this way I  can make an analysis and I think I would not change tool because I think that is a  great option to learn and more easily to take decisions that now in the world is  very important.\\n\\nClaudia Sarria.\\n\\n\""
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[14][\"full_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "txt = \"\"\"Reflection-Storytelling\n",
    "\n",
    "Challenge\n",
    "\n",
    "My friend Teresa was very anxious and unhappy recently and it was because of her son Naser. Naser is  10 years old and turned to be a little rebellious now. Due to the school closure in covid-19, Naser  has classes online and he then formed a habit of spending much on computers playing games or  watching videos he likes. Teresa was at work and can not monitor her son during working hours,  and she worried about Naser’s health as he spent too much time on computers so he completed his  homework very late, so he slept very late and his eyesight is poor as well. Naser used to be a good  student and obedient son, and he agreed to lessen time on computers or cellphones, but he can  not always keep his words. That’s why Teresa worried. She is afraid he turned to a bad boy.\"\"\"\n",
    "\n",
    "with torch.inference_mode():\n",
    "    out = model(**tokenizer(txt, return_tensors=\"pt\").to(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '▁Reflection', '-', 'Story', 'telling', '▁Challenge', '▁My', '▁friend', '▁Teresa', '▁was', '▁very', '▁anxious', '▁and', '▁unhappy', '▁recently', '▁and', '▁it', '▁was', '▁because', '▁of', '▁her', '▁son', '▁Nas', 'er', '.', '▁Nas', 'er', '▁is', '▁10', '▁years', '▁old', '▁and', '▁turned', '▁to', '▁be', '▁a', '▁little', '▁rebellious', '▁now', '.', '▁Due', '▁to', '▁the', '▁school', '▁closure', '▁in', '▁co', 'vid', '-', '19', ',', '▁Nas', 'er', '▁has', '▁classes', '▁online', '▁and', '▁he', '▁then', '▁formed', '▁a', '▁habit', '▁of', '▁spending', '▁much', '▁on', '▁computers', '▁playing', '▁games', '▁or', '▁watching', '▁videos', '▁he', '▁likes', '.', '▁Teresa', '▁was', '▁at', '▁work', '▁and', '▁can', '▁not', '▁monitor', '▁her', '▁son', '▁during', '▁working', '▁hours', ',', '▁and', '▁she', '▁worried', '▁about', '▁Nas', 'er', '’', 's', '▁health', '▁as', '▁he', '▁spent', '▁too', '▁much', '▁time', '▁on', '▁computers', '▁so', '▁he', '▁completed', '▁his', '▁homework', '▁very', '▁late', ',', '▁so', '▁he', '▁slept', '▁very', '▁late', '▁and', '▁his', '▁eyesight', '▁is', '▁poor', '▁as', '▁well', '.', '▁Nas', 'er', '▁used', '▁to', '▁be', '▁a', '▁good', '▁student', '▁and', '▁obedient', '▁son', ',', '▁and', '▁he', '▁agreed', '▁to', '▁lessen', '▁time', '▁on', '▁computers', '▁or', '▁cellphones', ',', '▁but', '▁he', '▁can', '▁not', '▁always', '▁keep', '▁his', '▁words', '.', '▁That', '’', 's', '▁why', '▁Teresa', '▁worried', '.', '▁She', '▁is', '▁afraid', '▁he', '▁turned', '▁to', '▁a', '▁bad', '▁boy', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "t = tokenizer.tokenize(txt, add_special_tokens=True)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicholas/miniconda3/lib/python3.10/site-packages/transformers/pipelines/base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'NAME',\n",
       "  'score': 0.9283984,\n",
       "  'word': 'Naser',\n",
       "  'start': 120,\n",
       "  'end': 126},\n",
       " {'entity_group': 'NAME',\n",
       "  'score': 0.9362397,\n",
       "  'word': 'Naser',\n",
       "  'start': 127,\n",
       "  'end': 133},\n",
       " {'entity_group': 'NAME',\n",
       "  'score': 0.93965244,\n",
       "  'word': 'Naser',\n",
       "  'start': 231,\n",
       "  'end': 237},\n",
       " {'entity_group': 'NAME',\n",
       "  'score': 0.9480499,\n",
       "  'word': 'Naser',\n",
       "  'start': 450,\n",
       "  'end': 456},\n",
       " {'entity_group': 'NAME',\n",
       "  'score': 0.93483853,\n",
       "  'word': 'Naser',\n",
       "  'start': 601,\n",
       "  'end': 607}]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[CLS]', tensor([0.9986, 0.0014], device='cuda:0')),\n",
       " ('▁Reflection', tensor([9.9918e-01, 8.1709e-04], device='cuda:0')),\n",
       " ('-', tensor([9.9948e-01, 5.2194e-04], device='cuda:0')),\n",
       " ('Story', tensor([9.9950e-01, 5.0328e-04], device='cuda:0')),\n",
       " ('telling', tensor([9.9966e-01, 3.4206e-04], device='cuda:0')),\n",
       " ('▁Challenge', tensor([9.9952e-01, 4.7598e-04], device='cuda:0')),\n",
       " ('▁My', tensor([9.9927e-01, 7.3367e-04], device='cuda:0')),\n",
       " ('▁friend', tensor([9.9977e-01, 2.3051e-04], device='cuda:0')),\n",
       " ('▁Teresa', tensor([0.6272, 0.3728], device='cuda:0')),\n",
       " ('▁was', tensor([9.9991e-01, 9.3162e-05], device='cuda:0')),\n",
       " ('▁very', tensor([9.9982e-01, 1.7549e-04], device='cuda:0')),\n",
       " ('▁anxious', tensor([9.9979e-01, 2.0574e-04], device='cuda:0')),\n",
       " ('▁and', tensor([9.9993e-01, 6.9925e-05], device='cuda:0')),\n",
       " ('▁unhappy', tensor([9.9987e-01, 1.3465e-04], device='cuda:0')),\n",
       " ('▁recently', tensor([9.9978e-01, 2.2044e-04], device='cuda:0')),\n",
       " ('▁and', tensor([9.9974e-01, 2.5785e-04], device='cuda:0')),\n",
       " ('▁it', tensor([9.9958e-01, 4.1933e-04], device='cuda:0')),\n",
       " ('▁was', tensor([9.9964e-01, 3.6439e-04], device='cuda:0')),\n",
       " ('▁because', tensor([9.9991e-01, 9.0994e-05], device='cuda:0')),\n",
       " ('▁of', tensor([9.9983e-01, 1.7321e-04], device='cuda:0')),\n",
       " ('▁her', tensor([9.9955e-01, 4.5372e-04], device='cuda:0')),\n",
       " ('▁son', tensor([9.9987e-01, 1.2809e-04], device='cuda:0')),\n",
       " ('▁Nas', tensor([0.0768, 0.9232], device='cuda:0')),\n",
       " ('er', tensor([0.0664, 0.9336], device='cuda:0')),\n",
       " ('.', tensor([9.9966e-01, 3.3900e-04], device='cuda:0')),\n",
       " ('▁Nas', tensor([0.0652, 0.9348], device='cuda:0')),\n",
       " ('er', tensor([0.0623, 0.9377], device='cuda:0')),\n",
       " ('▁is', tensor([9.9988e-01, 1.1575e-04], device='cuda:0')),\n",
       " ('▁10', tensor([9.9957e-01, 4.3167e-04], device='cuda:0')),\n",
       " ('▁years', tensor([9.9990e-01, 9.7145e-05], device='cuda:0')),\n",
       " ('▁old', tensor([9.9992e-01, 8.2422e-05], device='cuda:0')),\n",
       " ('▁and', tensor([9.9976e-01, 2.3711e-04], device='cuda:0')),\n",
       " ('▁turned', tensor([0.9989, 0.0011], device='cuda:0')),\n",
       " ('▁to', tensor([9.9916e-01, 8.4238e-04], device='cuda:0')),\n",
       " ('▁be', tensor([9.9969e-01, 3.1250e-04], device='cuda:0')),\n",
       " ('▁a', tensor([9.9984e-01, 1.6222e-04], device='cuda:0')),\n",
       " ('▁little', tensor([9.9955e-01, 4.5286e-04], device='cuda:0')),\n",
       " ('▁rebellious', tensor([9.9983e-01, 1.7210e-04], device='cuda:0')),\n",
       " ('▁now', tensor([9.9973e-01, 2.7474e-04], device='cuda:0')),\n",
       " ('.', tensor([9.9982e-01, 1.7906e-04], device='cuda:0')),\n",
       " ('▁Due', tensor([9.9989e-01, 1.1089e-04], device='cuda:0')),\n",
       " ('▁to', tensor([9.9991e-01, 8.7122e-05], device='cuda:0')),\n",
       " ('▁the', tensor([9.9984e-01, 1.6486e-04], device='cuda:0')),\n",
       " ('▁school', tensor([9.9990e-01, 9.5013e-05], device='cuda:0')),\n",
       " ('▁closure', tensor([9.9990e-01, 9.9245e-05], device='cuda:0')),\n",
       " ('▁in', tensor([9.9947e-01, 5.3346e-04], device='cuda:0')),\n",
       " ('▁co', tensor([9.9923e-01, 7.6848e-04], device='cuda:0')),\n",
       " ('vid', tensor([9.9948e-01, 5.2086e-04], device='cuda:0')),\n",
       " ('-', tensor([9.9944e-01, 5.5799e-04], device='cuda:0')),\n",
       " ('19', tensor([9.9959e-01, 4.1026e-04], device='cuda:0')),\n",
       " (',', tensor([9.9991e-01, 8.6469e-05], device='cuda:0')),\n",
       " ('▁Nas', tensor([0.0612, 0.9388], device='cuda:0')),\n",
       " ('er', tensor([0.0595, 0.9405], device='cuda:0')),\n",
       " ('▁has', tensor([9.9980e-01, 1.9633e-04], device='cuda:0')),\n",
       " ('▁classes', tensor([9.9992e-01, 8.4458e-05], device='cuda:0')),\n",
       " ('▁online', tensor([9.9989e-01, 1.1409e-04], device='cuda:0')),\n",
       " ('▁and', tensor([9.9982e-01, 1.7608e-04], device='cuda:0')),\n",
       " ('▁he', tensor([9.9948e-01, 5.1955e-04], device='cuda:0')),\n",
       " ('▁then', tensor([9.9920e-01, 8.0471e-04], device='cuda:0')),\n",
       " ('▁formed', tensor([9.9957e-01, 4.3008e-04], device='cuda:0')),\n",
       " ('▁a', tensor([9.9991e-01, 9.1245e-05], device='cuda:0')),\n",
       " ('▁habit', tensor([9.9985e-01, 1.4742e-04], device='cuda:0')),\n",
       " ('▁of', tensor([9.9992e-01, 8.1245e-05], device='cuda:0')),\n",
       " ('▁spending', tensor([9.9994e-01, 5.5256e-05], device='cuda:0')),\n",
       " ('▁much', tensor([9.9967e-01, 3.2670e-04], device='cuda:0')),\n",
       " ('▁on', tensor([9.9994e-01, 6.2813e-05], device='cuda:0')),\n",
       " ('▁computers', tensor([9.9995e-01, 5.1987e-05], device='cuda:0')),\n",
       " ('▁playing', tensor([9.9996e-01, 4.4705e-05], device='cuda:0')),\n",
       " ('▁games', tensor([9.9996e-01, 3.6470e-05], device='cuda:0')),\n",
       " ('▁or', tensor([9.9991e-01, 8.5419e-05], device='cuda:0')),\n",
       " ('▁watching', tensor([9.9995e-01, 5.1826e-05], device='cuda:0')),\n",
       " ('▁videos', tensor([9.9994e-01, 5.6933e-05], device='cuda:0')),\n",
       " ('▁he', tensor([9.9986e-01, 1.4465e-04], device='cuda:0')),\n",
       " ('▁likes', tensor([9.9990e-01, 1.0273e-04], device='cuda:0')),\n",
       " ('.', tensor([9.9959e-01, 4.0510e-04], device='cuda:0')),\n",
       " ('▁Teresa', tensor([0.8385, 0.1615], device='cuda:0')),\n",
       " ('▁was', tensor([9.9974e-01, 2.5882e-04], device='cuda:0')),\n",
       " ('▁at', tensor([9.9963e-01, 3.6694e-04], device='cuda:0')),\n",
       " ('▁work', tensor([9.9983e-01, 1.6747e-04], device='cuda:0')),\n",
       " ('▁and', tensor([9.9949e-01, 5.0545e-04], device='cuda:0')),\n",
       " ('▁can', tensor([9.9911e-01, 8.9190e-04], device='cuda:0')),\n",
       " ('▁not', tensor([9.9958e-01, 4.1792e-04], device='cuda:0')),\n",
       " ('▁monitor', tensor([9.9986e-01, 1.3714e-04], device='cuda:0')),\n",
       " ('▁her', tensor([9.9957e-01, 4.2804e-04], device='cuda:0')),\n",
       " ('▁son', tensor([9.9975e-01, 2.4531e-04], device='cuda:0')),\n",
       " ('▁during', tensor([9.9973e-01, 2.6507e-04], device='cuda:0')),\n",
       " ('▁working', tensor([9.9937e-01, 6.2566e-04], device='cuda:0')),\n",
       " ('▁hours', tensor([9.9971e-01, 2.9078e-04], device='cuda:0')),\n",
       " (',', tensor([9.9973e-01, 2.7064e-04], device='cuda:0')),\n",
       " ('▁and', tensor([9.9958e-01, 4.2289e-04], device='cuda:0')),\n",
       " ('▁she', tensor([9.9930e-01, 7.0441e-04], device='cuda:0')),\n",
       " ('▁worried', tensor([9.9989e-01, 1.0735e-04], device='cuda:0')),\n",
       " ('▁about', tensor([9.9986e-01, 1.3911e-04], device='cuda:0')),\n",
       " ('▁Nas', tensor([0.0452, 0.9548], device='cuda:0')),\n",
       " ('er', tensor([0.0587, 0.9413], device='cuda:0')),\n",
       " ('’', tensor([9.9945e-01, 5.4911e-04], device='cuda:0')),\n",
       " ('s', tensor([9.9978e-01, 2.1813e-04], device='cuda:0')),\n",
       " ('▁health', tensor([9.9990e-01, 1.0166e-04], device='cuda:0')),\n",
       " ('▁as', tensor([9.9977e-01, 2.2645e-04], device='cuda:0')),\n",
       " ('▁he', tensor([9.9971e-01, 2.9166e-04], device='cuda:0')),\n",
       " ('▁spent', tensor([9.9991e-01, 9.4654e-05], device='cuda:0')),\n",
       " ('▁too', tensor([9.9988e-01, 1.2494e-04], device='cuda:0')),\n",
       " ('▁much', tensor([9.9989e-01, 1.0718e-04], device='cuda:0')),\n",
       " ('▁time', tensor([9.9992e-01, 8.2267e-05], device='cuda:0')),\n",
       " ('▁on', tensor([9.9992e-01, 7.5863e-05], device='cuda:0')),\n",
       " ('▁computers', tensor([9.9988e-01, 1.1625e-04], device='cuda:0')),\n",
       " ('▁so', tensor([9.9960e-01, 3.9961e-04], device='cuda:0')),\n",
       " ('▁he', tensor([9.9964e-01, 3.6197e-04], device='cuda:0')),\n",
       " ('▁completed', tensor([9.9978e-01, 2.2488e-04], device='cuda:0')),\n",
       " ('▁his', tensor([9.9987e-01, 1.3108e-04], device='cuda:0')),\n",
       " ('▁homework', tensor([9.9993e-01, 7.4851e-05], device='cuda:0')),\n",
       " ('▁very', tensor([9.9975e-01, 2.4710e-04], device='cuda:0')),\n",
       " ('▁late', tensor([9.9994e-01, 5.9175e-05], device='cuda:0')),\n",
       " (',', tensor([9.9968e-01, 3.2258e-04], device='cuda:0')),\n",
       " ('▁so', tensor([9.9942e-01, 5.7909e-04], device='cuda:0')),\n",
       " ('▁he', tensor([9.9957e-01, 4.3044e-04], device='cuda:0')),\n",
       " ('▁slept', tensor([9.9992e-01, 7.8121e-05], device='cuda:0')),\n",
       " ('▁very', tensor([9.9967e-01, 3.3312e-04], device='cuda:0')),\n",
       " ('▁late', tensor([9.9989e-01, 1.1078e-04], device='cuda:0')),\n",
       " ('▁and', tensor([9.9988e-01, 1.1911e-04], device='cuda:0')),\n",
       " ('▁his', tensor([9.9975e-01, 2.4732e-04], device='cuda:0')),\n",
       " ('▁eyesight', tensor([9.9987e-01, 1.3458e-04], device='cuda:0')),\n",
       " ('▁is', tensor([9.9988e-01, 1.2160e-04], device='cuda:0')),\n",
       " ('▁poor', tensor([9.9985e-01, 1.5331e-04], device='cuda:0')),\n",
       " ('▁as', tensor([9.9957e-01, 4.3444e-04], device='cuda:0')),\n",
       " ('▁well', tensor([9.9949e-01, 5.1495e-04], device='cuda:0')),\n",
       " ('.', tensor([9.9966e-01, 3.4167e-04], device='cuda:0')),\n",
       " ('▁Nas', tensor([0.0658, 0.9342], device='cuda:0')),\n",
       " ('er', tensor([0.0645, 0.9355], device='cuda:0')),\n",
       " ('▁used', tensor([9.9974e-01, 2.6438e-04], device='cuda:0')),\n",
       " ('▁to', tensor([9.9977e-01, 2.2911e-04], device='cuda:0')),\n",
       " ('▁be', tensor([9.9990e-01, 9.8962e-05], device='cuda:0')),\n",
       " ('▁a', tensor([9.9990e-01, 9.7472e-05], device='cuda:0')),\n",
       " ('▁good', tensor([9.9990e-01, 9.8408e-05], device='cuda:0')),\n",
       " ('▁student', tensor([9.9992e-01, 7.9146e-05], device='cuda:0')),\n",
       " ('▁and', tensor([9.9991e-01, 9.4720e-05], device='cuda:0')),\n",
       " ('▁obedient', tensor([9.9981e-01, 1.9337e-04], device='cuda:0')),\n",
       " ('▁son', tensor([9.9991e-01, 8.5883e-05], device='cuda:0')),\n",
       " (',', tensor([9.9985e-01, 1.4959e-04], device='cuda:0')),\n",
       " ('▁and', tensor([9.9986e-01, 1.4386e-04], device='cuda:0')),\n",
       " ('▁he', tensor([9.9962e-01, 3.8254e-04], device='cuda:0')),\n",
       " ('▁agreed', tensor([9.9987e-01, 1.3100e-04], device='cuda:0')),\n",
       " ('▁to', tensor([9.9992e-01, 8.1846e-05], device='cuda:0')),\n",
       " ('▁lessen', tensor([9.9969e-01, 3.0801e-04], device='cuda:0')),\n",
       " ('▁time', tensor([9.9993e-01, 7.0126e-05], device='cuda:0')),\n",
       " ('▁on', tensor([9.9997e-01, 3.4126e-05], device='cuda:0')),\n",
       " ('▁computers', tensor([9.9996e-01, 3.7703e-05], device='cuda:0')),\n",
       " ('▁or', tensor([9.9995e-01, 4.8900e-05], device='cuda:0')),\n",
       " ('▁cellphones', tensor([9.9981e-01, 1.9393e-04], device='cuda:0')),\n",
       " (',', tensor([9.9978e-01, 2.1784e-04], device='cuda:0')),\n",
       " ('▁but', tensor([9.9986e-01, 1.3898e-04], device='cuda:0')),\n",
       " ('▁he', tensor([9.9944e-01, 5.5981e-04], device='cuda:0')),\n",
       " ('▁can', tensor([9.9960e-01, 4.0078e-04], device='cuda:0')),\n",
       " ('▁not', tensor([9.9976e-01, 2.4417e-04], device='cuda:0')),\n",
       " ('▁always', tensor([9.9974e-01, 2.5879e-04], device='cuda:0')),\n",
       " ('▁keep', tensor([9.9988e-01, 1.2175e-04], device='cuda:0')),\n",
       " ('▁his', tensor([9.9956e-01, 4.3677e-04], device='cuda:0')),\n",
       " ('▁words', tensor([9.9984e-01, 1.6031e-04], device='cuda:0')),\n",
       " ('.', tensor([9.9965e-01, 3.4738e-04], device='cuda:0')),\n",
       " ('▁That', tensor([9.9958e-01, 4.2429e-04], device='cuda:0')),\n",
       " ('’', tensor([9.9930e-01, 6.9849e-04], device='cuda:0')),\n",
       " ('s', tensor([0.9989, 0.0011], device='cuda:0')),\n",
       " ('▁why', tensor([9.9966e-01, 3.4308e-04], device='cuda:0')),\n",
       " ('▁Teresa', tensor([0.8993, 0.1007], device='cuda:0')),\n",
       " ('▁worried', tensor([9.9987e-01, 1.2662e-04], device='cuda:0')),\n",
       " ('.', tensor([9.9970e-01, 2.9959e-04], device='cuda:0')),\n",
       " ('▁She', tensor([9.9935e-01, 6.5367e-04], device='cuda:0')),\n",
       " ('▁is', tensor([9.9959e-01, 4.1318e-04], device='cuda:0')),\n",
       " ('▁afraid', tensor([9.9987e-01, 1.2912e-04], device='cuda:0')),\n",
       " ('▁he', tensor([9.9961e-01, 3.9221e-04], device='cuda:0')),\n",
       " ('▁turned', tensor([9.9961e-01, 3.8634e-04], device='cuda:0')),\n",
       " ('▁to', tensor([9.9943e-01, 5.7374e-04], device='cuda:0')),\n",
       " ('▁a', tensor([9.9980e-01, 2.0253e-04], device='cuda:0')),\n",
       " ('▁bad', tensor([9.9993e-01, 6.6360e-05], device='cuda:0')),\n",
       " ('▁boy', tensor([9.9989e-01, 1.0747e-04], device='cuda:0')),\n",
       " ('.', tensor([0.9977, 0.0023], device='cuda:0')),\n",
       " ('[SEP]', tensor([0.9984, 0.0016], device='cuda:0'))]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = out.logits.softmax(-1).reshape(-1, 2)\n",
    "\n",
    "list(zip(t, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Design Thinking for Innovation\\n\\nof University of Virginia\\n\\nFinal assignment by Zia\\n\\nVisualization Tool of Week 1 selected.\\n\\nWhat do have pizza and 5G in common ?\\n\\nChallenge: I am working at a international telco in the cellular business. We provide connectivity for  our customers via cellular networks since decades. As the application and the requirements of  customers besides plain telephony and SMS has significantly changed to “mobile Broadband” with  Smartphones in the 4th generation of cellular networks (4G, LTE), the 5th generation (5G) sets the aim  of getting the Industry connected. The demands of the industry are very different to the mobile  broadband demands as latency plays the most significant role (e.g. in a production environment). To  convince the management of changing certain things in the 4G networks to cope better with the  demands of 5G (and the vertical customers, i.e. industry) an approach was needed to explain the  need for certain changes.\\n\\nSelection: As technical content often needs illustration or analogies to be understood by  management (e.g. of the CEO is a financial guy and not an engineer) I have thought about either   choosing “Visualization” or” Story Telling” as tool to convince the management about needed  changes. I selected “Visualization” as visuals get easier into the brain and keep more easily (see video  6 in week 1 at 06:15 mins “Pictures and images enable us to not only help people understand what it  is we're trying to do, but to help really persuade them in the worthiness of, of, that particular idea, or,  or, the strength of, of that concept.”)\\n\\nApplication: So the question is “What do have pizza and 5G in common ?”\\n\\nThis sounds already like a funny question, so it attracts already the interest of the audience !\\n\\nThe answer is easy: deliver pizza / data fast !\\n\\nWe all know that there is nothing more annoying than ordering a pizza via internet or phone at you  favorite pizzeria and once it is delivered to your house it is cold already ! So the problem is that the  pizza gets colder as longer the way to travel is (from the pizzeria to your house). The solution is  straight forward, but might need a change of what we and the pizza business are used to today: so  how can one guarantee that the pizza, once ordered, is delivered still being hot ? … There are  multiple ways, but I use one particular to illustrate: This is “one needs to shorten the delivery  distance !” ... Ok, it is clear to everyone that delivering a pizza from 20 km distance is more  challenging then from 3 km and as longer the travel as colder the pizza is. The obvious choice for  improving the situation is to get closer to the customer with the pizza baking place ! The analogy for  cellular networks is that data processing is done in a node called UPF (user plane function in 5G).\\n\\nThis UPF is typically deployed once per city (bigger cities like New York might even have a dozen). But  the main information is that they are centrally build where the (smartphone traffic is). So, for an  industry plant in the suburbs of NY this is a problem, as they might need extremely low latency for  their production environment (called URLLC – Ultra Low Latency and Reliable Communication in 5G).\\n\\nSo, like the pizza delivery in the example about the need is clear: reduce the latency for pizza / data  delivery to meet the requirement of a hot pizza / data delivery in 1ms. So similar to building multiple  pizzeria across the city, the cellular 5G networks needs to be re-architected to place multiple UPF to  place where low latency is needed.\\n\\nInsight: I was quite successful when explain this pizza visualization on a white board to my  management !  … And every time they order in the COVID situation we are currently in a pizza for  business lunch, they remember my Design Thinking visualization !\\n\\nApproach: The reflections I got with using this visualization were extremely motivating that as apply  such analogies from every-day-life to technical content more often when talking to none-technicians  ---\\n\\n\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[18][\"full_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'NAME',\n",
       "  'score': 0.6830238,\n",
       "  'word': 'Alex',\n",
       "  'start': 21,\n",
       "  'end': 26},\n",
       " {'entity_group': 'NAME',\n",
       "  'score': 0.98529845,\n",
       "  'word': 'Uararo',\n",
       "  'start': 45,\n",
       "  'end': 52}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl(\"My name is Charmaine. Alex is my brother. And Uararo, a local artist, captures the lively scene on canvas, her brushstrokes bold and vibrant.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
