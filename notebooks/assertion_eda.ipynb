{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "dotenv_path = Path(\"../../.env\")\n",
    "if dotenv_path.exists():\n",
    "    print(\"Loaded .env file!\")\n",
    "    load_dotenv(str(dotenv_path))\n",
    "\n",
    "\n",
    "data = json.load(open(Path(os.environ[\"PROJECT_HOME_DIR\"]) / \"data/train.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163888, 13668, 4992533)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = list()\n",
    "\n",
    "total_num_tokens = 0\n",
    "\n",
    "for d in data:\n",
    "    matches.extend(list(set([x for x in d[\"tokens\"] if x.istitle() and len(x) > 2])))\n",
    "    total_num_tokens += len(d[\"tokens\"])\n",
    "\n",
    "len(matches), len(set(matches)), total_num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What',\n",
       " 'Éditions',\n",
       " 'Annex1',\n",
       " 'Application',\n",
       " 'Approach',\n",
       " 'Annex',\n",
       " 'This',\n",
       " 'Mind',\n",
       " 'The',\n",
       " 'Thinking',\n",
       " 'Avril',\n",
       " 'Around',\n",
       " 'After',\n",
       " 'Creativity',\n",
       " 'They',\n",
       " 'Buzan',\n",
       " 'According',\n",
       " 'Paris',\n",
       " 'Sylla',\n",
       " 'Dessine']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c997d00c25443e934444ca5a206cf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\", torch_dtype=torch.float16, device_map=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "s = slice(0, 20)\n",
    "\n",
    "prompt = '[INST] You are an expert at identifying names.\\n# Context\\n{context}\\n\\nIn the above context, could \"{name}\" be a first or last name? Respond Yes/No [/INST]'\n",
    "prompts = [prompt.format(name=name, context=\" \".join(ctx)) for name, ctx in zip(matches[s], [\"\"]*len(matches[s]))]\n",
    "\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs.to(model.device)).logits[:, -1, :].softmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What', 'Éditions', 'Annex1', 'Application', 'Approach', 'Annex', 'This', 'Mind', 'The', 'Thinking', 'Avril', 'Around', 'After', 'Creativity', 'They', 'Buzan', 'According', 'Paris', 'Sylla', 'Dessine']\n"
     ]
    }
   ],
   "source": [
    "print(matches[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 32000])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 842, 1, 28705, 842] [1, 28705, 5081, 5592, 842, 9780, 28723, 5613] [1, 28705, 1770, 708, 842, 1510, 28723, 2501]\n",
      "['▁yes', '▁Yes', 'yes', 'Yes']\n",
      "['▁No', '▁no', 'no', 'No']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.encode([\".\", \" .\"]), tokenizer.encode(\" yes Yes .yes.Yes\"), tokenizer.encode(\" No no .no.No\"))\n",
    "\n",
    "yes_tokens = [5081, 5592, 9780, 5613]\n",
    "no_tokens = [1770, 708, 1510, 2501]\n",
    "\n",
    "print(tokenizer.convert_ids_to_tokens(yes_tokens))\n",
    "print(tokenizer.convert_ids_to_tokens(no_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.3000, 0.0000, 0.0000, 0.5900, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0900, 0.0000, 0.0000, 0.8400, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.2600, 0.0000, 0.0000, 0.5800, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.1500, 0.0000, 0.0000, 0.7800, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.2300, 0.0000, 0.0000, 0.6800, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.4500, 0.0000, 0.0000, 0.4700, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.2000, 0.0000, 0.0000, 0.5400, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.5400, 0.0000, 0.0000, 0.3600, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.1900, 0.0000, 0.0000, 0.7100, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.1800, 0.0000, 0.0000, 0.7400, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.7000, 0.0000, 0.0000, 0.1700, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.1200, 0.0000, 0.0000, 0.8200, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.2200, 0.0000, 0.0000, 0.6900, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.1100, 0.0000, 0.0000, 0.8600, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.2400, 0.0000, 0.0000, 0.5700, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.8000, 0.0000, 0.0000, 0.1100, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0900, 0.0000, 0.0000, 0.7700, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.6300, 0.0000, 0.0000, 0.2500, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.6500, 0.0000, 0.0000, 0.1800, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.4400, 0.0000, 0.0000, 0.3900, 0.0000, 0.0000, 0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[:, yes_tokens+no_tokens].round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What [0.3, 0.592]\n",
      "Éditions [0.095, 0.838]\n",
      "Annex1 [0.255, 0.575]\n",
      "Application [0.152, 0.782]\n",
      "Approach [0.226, 0.679]\n",
      "Annex [0.446, 0.471]\n",
      "This [0.203, 0.536]\n",
      "Mind [0.536, 0.36]\n",
      "The [0.191, 0.71]\n",
      "Thinking [0.182, 0.738]\n",
      "Avril [0.7, 0.174]\n",
      "Around [0.119, 0.816]\n",
      "After [0.22, 0.693]\n",
      "Creativity [0.108, 0.857]\n",
      "They [0.242, 0.568]\n",
      "Buzan [0.803, 0.113]\n",
      "According [0.091, 0.774]\n",
      "Paris [0.627, 0.246]\n",
      "Sylla [0.648, 0.183]\n",
      "Dessine [0.441, 0.389]\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "for p, _, l in zip(matches[s], [\"\"]*len(matches[s]), logits[:, [yes_tokens[1], no_tokens[0]]]):\n",
    "    print(p, list(map(partial(round, ndigits=3), l.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def get_preds(names, contexts=None):\n",
    "\n",
    "    if contexts is None:\n",
    "        contexts = [\"\"] * len(names)\n",
    "\n",
    "    prompt = '[INST] # Context\\n{context}\\n\\nIn the above context, could \"{name}\" be a first or last name? Respond Yes/No [/INST]'\n",
    "    prompts = [\n",
    "        prompt.format(name=name, context=ctx) for name, ctx in zip(names, contexts)\n",
    "    ]\n",
    "\n",
    "    inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "    bs = 32\n",
    "\n",
    "    all_probs = []\n",
    "    # [5592, 1770] _Yes, _No \n",
    "    # [5613, 2501] (yes, no)\n",
    "    yes_no_tokens = [5592, 1770] \n",
    "\n",
    "    for i in tqdm(range(0, len(inputs[\"input_ids\"]), bs)):\n",
    "        input_ids = inputs[\"input_ids\"][i : i + bs].to(model.device)\n",
    "        attention_mask = inputs[\"attention_mask\"][i : i + bs].to(model.device)\n",
    "\n",
    "        logits = model(input_ids, attention_mask=attention_mask).logits\n",
    "\n",
    "        probs = logits[:, -1, :].softmax(-1)[:, yes_no_tokens].cpu().tolist()\n",
    "\n",
    "        all_probs.extend(probs)\n",
    "\n",
    "    return all_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "683726abb88f421abd2b522034c7c719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/428 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unq_matches = list(set(matches))\n",
    "\n",
    "probs = get_preds(list(set(matches)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.2097785472869873, 0.6986692547798157],\n",
       " [0.5639786124229431, 0.36986619234085083],\n",
       " [0.483333021402359, 0.4400797188282013],\n",
       " [0.2821289896965027, 0.552381694316864],\n",
       " [0.6366611123085022, 0.22348907589912415],\n",
       " [0.4513509273529053, 0.4340599477291107],\n",
       " [0.7455400228500366, 0.15028692781925201],\n",
       " [0.25410473346710205, 0.653968334197998],\n",
       " [0.3341909945011139, 0.5298798084259033],\n",
       " [0.5592300891876221, 0.3261960446834564]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Defer',\n",
       " 'Champions',\n",
       " 'Query',\n",
       " 'My\\u200b',\n",
       " 'Rya',\n",
       " 'Fossil',\n",
       " 'Kings',\n",
       " 'Chai',\n",
       " 'Gulf',\n",
       " 'Konnect']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unq_matches = list(set(matches))\n",
    "unq_matches[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13668, 4733)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(probs), len([x for x in probs if x[0] > x[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1249"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_names = []\n",
    "\n",
    "for d in data:\n",
    "    for t, l in zip(d[\"tokens\"], d[\"labels\"]):\n",
    "        if \"NAME_STUDENT\" in l and len(t) > 2:\n",
    "            gt_names.append(t)\n",
    "\n",
    "len(set(gt_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"You are an expert name identifier.\\nIs the word \\\"{word}\\\" a name? Respond yes/no\\n\"\n",
    "1207/1249\n",
    "\n",
    "\"You are an expert name identifier.\\nCould \\\"{word}\\\" a first or last name? Respond yes/no\\n\"\n",
    "1247/1249"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13668\n",
      "4733\n",
      "False positives 3526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1249, 1207)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_matches = [y for x,y  in zip(probs, unq_matches) if x[0] > x[1]]\n",
    "missed = list(set(gt_names) - set(pos_matches))\n",
    "\n",
    "print(len(probs))\n",
    "print(len(pos_matches))\n",
    "print(\"False positives\", len(set(pos_matches) - set(gt_names)))\n",
    "\n",
    "len(set(gt_names) & (set(unq_matches))), len(set(gt_names) & (set(pos_matches)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee4411af5655423da3cba26d380ddb6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[[0.3675011098384857, 0.5062541365623474],\n",
       " [0.2925245761871338, 0.5465078353881836],\n",
       " [0.4013194441795349, 0.5033673048019409],\n",
       " [0.4014034867286682, 0.43402066826820374],\n",
       " [0.36264950037002563, 0.4340346157550812],\n",
       " [0.31771907210350037, 0.47695276141166687],\n",
       " [0.22140875458717346, 0.5437273979187012],\n",
       " [0.31792664527893066, 0.5756908059120178],\n",
       " [0.4214402735233307, 0.4965779483318329],\n",
       " [0.29537197947502136, 0.6253024339675903]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missed_probs = get_preds(missed)\n",
    "missed_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sin',\n",
       " 'Maga',\n",
       " 'Llamas',\n",
       " 'Jhonatan',\n",
       " 'Elnazer',\n",
       " 'Fofa',\n",
       " 'Dla',\n",
       " 'Corona',\n",
       " 'Yessica',\n",
       " 'Rehab',\n",
       " 'Buonincontro',\n",
       " 'Born',\n",
       " 'Yap',\n",
       " 'Juber',\n",
       " 'Street',\n",
       " 'Francy',\n",
       " 'Murcia',\n",
       " 'Asia',\n",
       " 'Sales',\n",
       " 'Frutos',\n",
       " 'Pink',\n",
       " 'Islam',\n",
       " 'Saly',\n",
       " 'Villa',\n",
       " 'Okey',\n",
       " 'Cuda',\n",
       " 'Zizza',\n",
       " 'Ramadan',\n",
       " 'Pong',\n",
       " 'Momentos',\n",
       " 'Maprok',\n",
       " 'Montenegro',\n",
       " 'Der',\n",
       " 'Peroni',\n",
       " 'Bhai',\n",
       " 'Papa',\n",
       " 'Bravo',\n",
       " 'Telfah',\n",
       " 'Sunday',\n",
       " 'Puerta',\n",
       " 'Barbie',\n",
       " 'Mossad']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With more context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens_before = 20\n",
    "num_tokens_after = 20\n",
    "\n",
    "contexts = []\n",
    "gt_names = []\n",
    "\n",
    "for d in data:\n",
    "    for i, (t, l) in enumerate(zip(d[\"tokens\"], d[\"labels\"])):\n",
    "        if \"NAME_STUDENT\" in l:\n",
    "            start = max(0, i - num_tokens_before)\n",
    "            end = min(len(d[\"tokens\"]), i + num_tokens_after)\n",
    "            contexts.append(d[\"tokens\"][start:end])\n",
    "            gt_names.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2461, 2461)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contexts), len(set([\"\".join(t) for t in contexts]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Walsh', 'Said', 'Catania', 'Brittany', 'Jackson', 'Gopal', 'Kumar', 'Jose', 'Luis', 'Llamas', 'Jose', 'Luis', 'Llamas', 'Oscar', 'Silvia', 'Cervantes', 'Carlos', 'Hernandez', 'Carlos', 'Hernandez']\n",
      "[['Mind', 'Mapping', '–', 'Reflection', '–', 'Robert', 'Walsh', '\\n\\n', '1', '.', 'Challenge', ':', 'Describe', 'your', 'challenge', ',', 'including', 'all', 'relevant', 'information', '.', '\\n\\n', 'I', 'wanted', 'to', 'apply'], ['Said', 'Catania', '\\n\\n', 'Peer', '-', 'graded', 'Assignment', ':', 'Reﬂection', '\\n\\n', 'October', '13', ',', '2020', '\\n\\n', 'Using', 'Visualization', '\\n\\n', 'As', 'a'], ['Said', 'Catania', '\\n\\n', 'Peer', '-', 'graded', 'Assignment', ':', 'Reﬂection', '\\n\\n', 'October', '13', ',', '2020', '\\n\\n', 'Using', 'Visualization', '\\n\\n', 'As', 'a', 'tool'], ['Using', 'Visualization', 'to', 'create', 'lessons', 'about', 'educational', 'platforms', '\\n\\n', 'by', 'Brittany', 'Jackson', '\\n\\n', 'Challenge', '\\n\\n', 'I', 'am', 'a', 'high', 'school', 'Spanish', 'teacher', '.', 'The', 'challenge', 'I', 'selected', 'was', 'how', 'to'], ['Using', 'Visualization', 'to', 'create', 'lessons', 'about', 'educational', 'platforms', '\\n\\n', 'by', 'Brittany', 'Jackson', '\\n\\n', 'Challenge', '\\n\\n', 'I', 'am', 'a', 'high', 'school', 'Spanish', 'teacher', '.', 'The', 'challenge', 'I', 'selected', 'was', 'how', 'to', 'create'], ['affordable', 'medicines', 'were', 'made', 'available', 'to', 'patients', 'across', ' ', 'the', 'length', 'and', 'breadth', 'of', 'these', 'states', '.', '\\n\\n', 'Submitted', 'by', 'Gopal', 'Kumar', 'on', '31st', 'January', '2021', '\\n\\n'], ['medicines', 'were', 'made', 'available', 'to', 'patients', 'across', ' ', 'the', 'length', 'and', 'breadth', 'of', 'these', 'states', '.', '\\n\\n', 'Submitted', 'by', 'Gopal', 'Kumar', 'on', '31st', 'January', '2021', '\\n\\n'], ['of', 'Virginia', 'Darden', 'Business', 'School', 'Nancy', 'Gonsalez', '\\n\\n', 'of', ' ', '1', '2', 'Design', 'Thinking', 'for', 'Innovation', '\\n\\n', 'FINAL', 'ASSIGNMENT', '\\n\\n', 'Jose', 'Luis', 'Llamas', '\\n\\n', 'November', '22', ',', '2020', '\\n\\n', 'Storytelling', 'Applied', 'as', 'Design', 'Thinking', 'Tool', 'to', 'Solve', 'a', 'Challenge', ':'], ['Virginia', 'Darden', 'Business', 'School', 'Nancy', 'Gonsalez', '\\n\\n', 'of', ' ', '1', '2', 'Design', 'Thinking', 'for', 'Innovation', '\\n\\n', 'FINAL', 'ASSIGNMENT', '\\n\\n', 'Jose', 'Luis', 'Llamas', '\\n\\n', 'November', '22', ',', '2020', '\\n\\n', 'Storytelling', 'Applied', 'as', 'Design', 'Thinking', 'Tool', 'to', 'Solve', 'a', 'Challenge', ':', '\\n\\n'], ['Darden', 'Business', 'School', 'Nancy', 'Gonsalez', '\\n\\n', 'of', ' ', '1', '2', 'Design', 'Thinking', 'for', 'Innovation', '\\n\\n', 'FINAL', 'ASSIGNMENT', '\\n\\n', 'Jose', 'Luis', 'Llamas', '\\n\\n', 'November', '22', ',', '2020', '\\n\\n', 'Storytelling', 'Applied', 'as', 'Design', 'Thinking', 'Tool', 'to', 'Solve', 'a', 'Challenge', ':', '\\n\\n', 'Monocultural'], ['of', 'Virginia', 'Darden', 'Business', 'School', 'Nancy', 'Gonsalez', '\\n\\n', 'of', ' ', '2', '2', 'Design', 'Thinking', 'for', 'Innovation', '\\n\\n', 'FINAL', 'ASSIGNMENT', '\\n\\n', 'Jose', 'Luis', 'Llamas', '\\n\\n', 'November', '22', ',', '2020', '\\n\\n', 'Selected', 'Tool', ':', ' ', 'Storytelling', '.', '\\n\\n', 'We', 'believe', 'storytelling', 'is'], ['Virginia', 'Darden', 'Business', 'School', 'Nancy', 'Gonsalez', '\\n\\n', 'of', ' ', '2', '2', 'Design', 'Thinking', 'for', 'Innovation', '\\n\\n', 'FINAL', 'ASSIGNMENT', '\\n\\n', 'Jose', 'Luis', 'Llamas', '\\n\\n', 'November', '22', ',', '2020', '\\n\\n', 'Selected', 'Tool', ':', ' ', 'Storytelling', '.', '\\n\\n', 'We', 'believe', 'storytelling', 'is', 'the'], ['Darden', 'Business', 'School', 'Nancy', 'Gonsalez', '\\n\\n', 'of', ' ', '2', '2', 'Design', 'Thinking', 'for', 'Innovation', '\\n\\n', 'FINAL', 'ASSIGNMENT', '\\n\\n', 'Jose', 'Luis', 'Llamas', '\\n\\n', 'November', '22', ',', '2020', '\\n\\n', 'Selected', 'Tool', ':', ' ', 'Storytelling', '.', '\\n\\n', 'We', 'believe', 'storytelling', 'is', 'the', 'perfect'], ['Design', 'Thinking', 'for', 'Innovation', '  ', 'Final', 'Assignment', ' ', '21', 'October', '2018', '-', 'Oscar', '\\n\\n', 'Background', '\\n\\n', 'I', 'work', 'as', 'a', 'UX', 'Designer', 'at', 'a', 'digital', 'agency', ',', 'working', 'with', 'clients', 'from', 'various'], ['STUDENT', ':', 'Silvia', 'Cervantes', '\\n\\n', 'TOOL', 'SELECTED', ':', 'MIND', '-', 'MAPPING', '\\n\\n', 'Challenge', ':', 'Describe', 'your', 'challenge', ',', 'including', 'all', 'relevant', 'information'], ['STUDENT', ':', 'Silvia', 'Cervantes', '\\n\\n', 'TOOL', 'SELECTED', ':', 'MIND', '-', 'MAPPING', '\\n\\n', 'Challenge', ':', 'Describe', 'your', 'challenge', ',', 'including', 'all', 'relevant', 'information', '.'], ['Carlos', 'Hernandez', '\\n\\n', 'Rehabilitation', '-', 'Storytelling', '\\n\\n', 'Challenge', '&', 'Selection', '\\n\\n', 'The', 'healthcare', 'sector', 'and', 'more', 'specifically', 'the', 'rehabilitation', 'technologies'], ['Carlos', 'Hernandez', '\\n\\n', 'Rehabilitation', '-', 'Storytelling', '\\n\\n', 'Challenge', '&', 'Selection', '\\n\\n', 'The', 'healthcare', 'sector', 'and', 'more', 'specifically', 'the', 'rehabilitation', 'technologies', 'have'], ['this', 'experience', 'of', 'the', 'rehabilitation', 'the', 'kid', 'had', 'a', ' ', 'series', 'of', 'bad', 'experiences', 'that', 'can', 'be', 'changed', '.', '\\n\\n', 'Carlos', 'Hernandez', '\\n\\n', 'One', 'approach', 'and', 'the', 'one', 'that', 'we', 'followed', ',', 'change', 'the', 'rehabilitation', 'machines', 'to', 'be', ' ', 'more'], ['experience', 'of', 'the', 'rehabilitation', 'the', 'kid', 'had', 'a', ' ', 'series', 'of', 'bad', 'experiences', 'that', 'can', 'be', 'changed', '.', '\\n\\n', 'Carlos', 'Hernandez', '\\n\\n', 'One', 'approach', 'and', 'the', 'one', 'that', 'we', 'followed', ',', 'change', 'the', 'rehabilitation', 'machines', 'to', 'be', ' ', 'more', 'friendly']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.7300, 0.0000, 0.0000, 0.1400, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.5200, 0.0000, 0.0000, 0.3500, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.6300, 0.0000, 0.0000, 0.2800, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.7000, 0.0000, 0.0000, 0.1900, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.7000, 0.0000, 0.0000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.5500, 0.0000, 0.0000, 0.2700, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.6100, 0.0000, 0.0000, 0.1900, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.4800, 0.0000, 0.0000, 0.4400, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.4800, 0.0000, 0.0000, 0.4500, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.5400, 0.0000, 0.0000, 0.3900, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.4600, 0.0000, 0.0000, 0.3700, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.4200, 0.0000, 0.0000, 0.4600, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.5800, 0.0000, 0.0000, 0.3400, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.7900, 0.0000, 0.0000, 0.0900, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.7600, 0.0000, 0.0000, 0.1400, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.7000, 0.0000, 0.0000, 0.1400, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.7200, 0.0000, 0.0000, 0.1900, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.7300, 0.0000, 0.0000, 0.1300, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.6900, 0.0000, 0.0000, 0.2100, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.6700, 0.0000, 0.0000, 0.2300, 0.0000, 0.0000, 0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = slice(-20, None)\n",
    "\n",
    "prompt = '[INST] # Context\\n{context}\\n\\nIn the above context, could \"{name}\" be a first or last name? Respond Yes/No [/INST]'\n",
    "prompts = [prompt.format(name=name, context=\" \".join(ctx)) for name, ctx in zip(gt_names[s], contexts[s])]\n",
    "\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs.to(model.device)).logits[:, -1, :].softmax(-1)\n",
    "\n",
    "print(gt_names[s])\n",
    "print(contexts[s])\n",
    "\n",
    "logits[:, yes_tokens+no_tokens].round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  thus facilitating the implementation of related actions . \n",
      "\n",
      " Design Thinking for innovation reflexion - Avril 2021 - Nathalie Sylla \n",
      "\n",
      " Annex 1 : Mind Map Shared facilities project \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e09c946194545259b1999f4acb56c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[[0.32757481932640076, 0.6119903326034546],\n",
       " [0.07549765706062317, 0.8984438180923462],\n",
       " [0.6531009078025818, 0.270134299993515],\n",
       " [0.7930570244789124, 0.15616217255592346],\n",
       " [0.3426230847835541, 0.3453103303909302]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx = [\" \".join(contexts[5])]*5\n",
    "print(ctx[0])\n",
    "n = [\"Design\", \"Thinking\", \"Avril\", \"Sylla\", \" \", \" \"]\n",
    "\n",
    "get_preds(n, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e52371478ea04a0eab8d768e9c048901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/77 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with_ctx = get_preds(gt_names, [\" \".join(c) for c in contexts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2426, 2461)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([x[0] > x[1] for x in with_ctx]), len(with_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Design',\n",
       " 'Challenge',\n",
       " 'Design',\n",
       " 'Avril',\n",
       " 'Design',\n",
       " 'Design',\n",
       " 'The',\n",
       " 'Design',\n",
       " 'This',\n",
       " 'This']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "negatives = []\n",
    "\n",
    "for gt, ctx in zip(gt_names, contexts):\n",
    "    titled = [x for x in ctx if x.istitle() and len(x) > 2 and x not in gt_names]\n",
    "    if len(titled) > 0:\n",
    "        negatives.append(random.choice(titled))\n",
    "    else:\n",
    "        rand = random.choice(ctx)\n",
    "        while rand in gt_names:\n",
    "            rand = random.choice(ctx)\n",
    "        negatives.append(rand)\n",
    "\n",
    "negatives[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8250aee5d4fc4865819ee1f695fba70e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/77 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "neg_with_ctx = get_preds(negatives, [\" \".join(c) for c in contexts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(234, 2461)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([x[0] > x[1] for x in neg_with_ctx]), len(neg_with_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avril [0.6200621128082275, 0.29061728715896606]\n",
      "The [0.4301931858062744, 0.4169575273990631]\n",
      "Gitam [0.5238758325576782, 0.4079948961734772]\n",
      "Vice [0.4675936698913574, 0.37572208046913147]\n",
      "The [0.4841519296169281, 0.2780250608921051]\n",
      "Name [0.8964372873306274, 0.040955688804388046]\n",
      "Interviewer [0.7718675136566162, 0.14846888184547424]\n",
      "Interviewee [0.5190407633781433, 0.36805498600006104]\n",
      "Kasyap [0.48509907722473145, 0.3719383776187897]\n",
      "General [0.45022788643836975, 0.43297991156578064]\n",
      "The [0.45732221007347107, 0.4099409580230713]\n",
      "my [0.6711328625679016, 0.17783252894878387]\n",
      "Wise [0.5046449899673462, 0.39920708537101746]\n",
      "Wise [0.4775359332561493, 0.4148904085159302]\n",
      "member [0.48131704330444336, 0.41817548871040344]\n",
      "\n",
      "\n",
      " [0.40514621138572693, 0.2918158769607544]\n",
      "P [0.8111827373504639, 0.11505018174648285]\n",
      "By [0.6241849064826965, 0.2748248875141144]\n",
      "Lengua [0.4959598779678345, 0.3516882061958313]\n",
      "Profesor [0.45655497908592224, 0.3366425633430481]\n",
      "Example [0.46362417936325073, 0.3365550637245178]\n",
      "Visualization [0.5444309711456299, 0.4077599346637726]\n",
      "The [0.3854236602783203, 0.3677738308906555]\n",
      "Name [0.8255638480186462, 0.08499811589717865]\n",
      "Name [0.8532529473304749, 0.06683193892240524]\n",
      "Example [0.5497331619262695, 0.33868077397346497]\n",
      "The [0.462848961353302, 0.3333776295185089]\n",
      "Peer [0.5223219990730286, 0.4067848026752472]\n",
      "Example [0.4864351451396942, 0.34224987030029297]\n",
      "Interviewer [0.8114537596702576, 0.11781786382198334]\n",
      "Interviewer [0.783235490322113, 0.14716559648513794]\n",
      "Name [0.9395608901977539, 0.0209204088896513]\n",
      "My [0.42343810200691223, 0.3795674741268158]\n",
      "​I​ [0.5045812726020813, 0.3522544801235199]\n",
      "The [0.5054081678390503, 0.32125699520111084]\n",
      "The [0.5761597156524658, 0.2700406312942505]\n",
      "Peer [0.6969847679138184, 0.24466466903686523]\n",
      "Peer [0.680057942867279, 0.2684032618999481]\n",
      "Peer [0.5741356015205383, 0.32206088304519653]\n",
      "Peer [0.5167638659477234, 0.3496599495410919]\n",
      "Peer [0.5538390874862671, 0.3205374777317047]\n",
      "Minh [0.6016841530799866, 0.3170652687549591]\n",
      "Manager [0.5339077711105347, 0.3936789333820343]\n",
      "Manager [0.5498731732368469, 0.3868841230869293]\n",
      "The [0.41047704219818115, 0.288806676864624]\n",
      "The [0.39722633361816406, 0.3371216058731079]\n",
      "Example [0.4367244243621826, 0.43332579731941223]\n",
      "Last [0.45520931482315063, 0.4309835135936737]\n",
      "The [0.4090083837509155, 0.3525872528553009]\n",
      "Artists [0.5053029656410217, 0.3500131368637085]\n",
      "Artist [0.6377450227737427, 0.2658516764640808]\n",
      "Mentor [0.5532143115997314, 0.36852020025253296]\n",
      "The [0.23931875824928284, 0.20152661204338074]\n",
      "Manager [0.5325528383255005, 0.40199196338653564]\n",
      "You [0.5060314536094666, 0.39718863368034363]\n",
      "The [0.4452262818813324, 0.28745970129966736]\n",
      "The [0.6841647624969482, 0.17030209302902222]\n",
      "The [0.3920780122280121, 0.33536210656166077]\n",
      "Instructor [0.7915869951248169, 0.154659703373909]\n",
      "Name [0.8402100801467896, 0.09280744940042496]\n",
      "The [0.43495458364486694, 0.4282112419605255]\n",
      "Students [0.554326593875885, 0.3992665112018585]\n",
      "Director [0.7959385514259338, 0.13510935008525848]\n",
      "Interviewer [0.658043622970581, 0.2256440371274948]\n",
      "Interviewee [0.591715931892395, 0.32677653431892395]\n",
      "Interviewee [0.6260421276092529, 0.29113662242889404]\n",
      "Institute [0.6237867474555969, 0.2661994993686676]\n",
      "Institute [0.5753175020217896, 0.289287805557251]\n",
      "Interviewer [0.8114113211631775, 0.12939085066318512]\n",
      "Interviewer [0.8064380288124084, 0.11893350630998611]\n",
      "Name [0.9317857623100281, 0.02643272839486599]\n",
      "From [0.5279131531715393, 0.3152313530445099]\n",
      "Abu [0.5478181838989258, 0.3072981536388397]\n",
      "Author [0.6702134609222412, 0.24273522198200226]\n",
      "Author [0.8033187389373779, 0.13743163645267487]\n",
      "Author [0.8098551034927368, 0.13117638230323792]\n",
      "Team [0.48755568265914917, 0.4170284867286682]\n",
      "Interviewer [0.7627338171005249, 0.15495876967906952]\n",
      "Interviewer [0.7172431349754333, 0.20389443635940552]\n",
      "Interviewer [0.7171916365623474, 0.20871464908123016]\n",
      "Interviewer [0.6359027028083801, 0.22851642966270447]\n",
      "Name [0.9077122211456299, 0.0459040030837059]\n",
      "Interviewer [0.6153954863548279, 0.2585470676422119]\n",
      "The [0.5466408729553223, 0.2791968584060669]\n",
      "Mind [0.4959432780742645, 0.3685537576675415]\n",
      "Human [0.6193550229072571, 0.23325125873088837]\n",
      "Reflection [0.4793758690357208, 0.4330800175666809]\n",
      "Team [0.6205726265907288, 0.27537745237350464]\n",
      "Interviewer [0.7799506783485413, 0.12437400966882706]\n",
      "The [0.5119031667709351, 0.32793745398521423]\n",
      "Example [0.4278971254825592, 0.4019721448421478]\n",
      "Federation [0.46129393577575684, 0.3677755892276764]\n",
      "The [0.41922101378440857, 0.400023490190506]\n",
      "Author [0.7549901008605957, 0.18073232471942902]\n",
      "The [0.3889037072658539, 0.3710945248603821]\n",
      "The [0.40266427397727966, 0.3637768626213074]\n",
      "The [0.4342660903930664, 0.42420634627342224]\n",
      "Name [0.7940026521682739, 0.08634378761053085]\n",
      "Name [0.7979161143302917, 0.06152868643403053]\n",
      "Savitribai [0.44985735416412354, 0.43262359499931335]\n",
      "Name [0.9324699640274048, 0.024273844435811043]\n",
      "Name [0.9297540187835693, 0.024584289640188217]\n",
      "Interviewee [0.7854469418525696, 0.15957322716712952]\n",
      "Project [0.4730551838874817, 0.4409359097480774]\n",
      "The [0.5202630162239075, 0.2616046667098999]\n",
      "References [0.5688711404800415, 0.28382036089897156]\n",
      "PERSON [0.5706301927566528, 0.35155507922172546]\n",
      "Example [0.48802489042282104, 0.33021417260169983]\n",
      "Name [0.8016358017921448, 0.1360764503479004]\n",
      "Rob [0.7151041030883789, 0.17939957976341248]\n",
      "Name [0.9300655126571655, 0.0396069698035717]\n",
      "Name [0.9441918134689331, 0.03576221689581871]\n",
      "Peer [0.46138066053390503, 0.4471854567527771]\n",
      "Abuja [0.43365007638931274, 0.37382975220680237]\n",
      "The [0.47792109847068787, 0.26600316166877747]\n",
      "The [0.4298703670501709, 0.3144998550415039]\n",
      "This [0.34365931153297424, 0.2962528169155121]\n",
      "Name [0.9322296380996704, 0.025432217866182327]\n",
      "Name [0.9333148002624512, 0.024486390873789787]\n",
      "The [0.5673995614051819, 0.30848976969718933]\n",
      "The [0.5317482948303223, 0.340650737285614]\n",
      "The [0.5748611092567444, 0.31746840476989746]\n",
      "The [0.5555930137634277, 0.32917800545692444]\n",
      "us [0.5455645322799683, 0.34950175881385803]\n",
      "Name [0.8709025979042053, 0.08690734952688217]\n",
      "Savitribai [0.5473657250404358, 0.31187957525253296]\n",
      "Building [0.41821205615997314, 0.402190625667572]\n",
      "\n",
      "\n",
      " [0.3492973744869232, 0.3307081162929535]\n",
      "Selection [0.7841830253601074, 0.14734362065792084]\n",
      "One [0.661649227142334, 0.2758164405822754]\n",
      "their [0.6517630219459534, 0.23421595990657806]\n",
      "Client [0.4073858857154846, 0.35394299030303955]\n",
      "Darden [0.5348656177520752, 0.37049058079719543]\n",
      "Design [0.5380215644836426, 0.37559959292411804]\n",
      "Name [0.8201278448104858, 0.09346482902765274]\n",
      "The [0.5259466767311096, 0.3847908079624176]\n",
      "Example [0.43912360072135925, 0.4323156476020813]\n",
      "Dr. [0.5309966206550598, 0.2776380479335785]\n",
      "Myself [0.40552693605422974, 0.3635120093822479]\n",
      "The [0.4065534174442291, 0.3266748785972595]\n",
      "Master [0.5991421937942505, 0.2942887544631958]\n",
      "The [0.5741571187973022, 0.21963466703891754]\n",
      "The [0.5435236096382141, 0.26489225029945374]\n",
      "The [0.4826754629611969, 0.3044195771217346]\n",
      "Name [0.8038095831871033, 0.10543686896562576]\n",
      "Name [0.8028808236122131, 0.09008073061704636]\n",
      "Trainer [0.6067323684692383, 0.3298746645450592]\n",
      "Aunt [0.829692542552948, 0.1046626940369606]\n",
      "Trabzonspor [0.518578052520752, 0.3883970081806183]\n",
      "Sörloth [0.5312705039978027, 0.33506807684898376]\n",
      "The [0.46099600195884705, 0.3399171531200409]\n",
      "The [0.5091703534126282, 0.27683112025260925]\n",
      "One [0.61448734998703, 0.3393521308898926]\n",
      "new [0.734606146812439, 0.22404220700263977]\n",
      "Learning [0.5456767082214355, 0.3992255628108978]\n",
      "User [0.599770188331604, 0.34441903233528137]\n",
      "Buyer [0.5586371421813965, 0.39613303542137146]\n",
      "Buyer [0.5536710023880005, 0.4019220471382141]\n",
      "Renter [0.46256566047668457, 0.458965927362442]\n",
      "Name [0.9127042293548584, 0.033505991101264954]\n",
      "Name [0.9296689033508301, 0.026372678577899933]\n",
      "Name [0.888416051864624, 0.03964897617697716]\n",
      "Interviewee [0.546808660030365, 0.33952122926712036]\n",
      "Interviewer [0.5633144378662109, 0.28547385334968567]\n",
      "Interviewee [0.6117031574249268, 0.288948118686676]\n",
      "Interviewer [0.5690641403198242, 0.3217197060585022]\n",
      "Grandmother [0.6511127352714539, 0.17252770066261292]\n",
      "Interviewee [0.7287629246711731, 0.1976822465658188]\n",
      "Team [0.4652024507522583, 0.4438993036746979]\n",
      "Interviewee [0.7652591466903687, 0.15915873646736145]\n",
      "Student [0.7152665257453918, 0.2590523660182953]\n",
      "Name [0.8460766673088074, 0.08056364208459854]\n",
      "User [0.581998348236084, 0.30669161677360535]\n",
      "Name [0.8173235654830933, 0.10391102731227875]\n",
      "Mr. [0.7161304950714111, 0.1661556363105774]\n",
      "One [0.6589049696922302, 0.25009211897850037]\n",
      "By [0.6024534106254578, 0.33794572949409485]\n",
      "Alexandr [0.5588304400444031, 0.33631008863449097]\n",
      "One [0.5015427470207214, 0.3967529833316803]\n",
      "The [0.5395259261131287, 0.28654006123542786]\n",
      "Founder [0.4591993987560272, 0.402088463306427]\n",
      "The [0.4753369688987732, 0.3588031530380249]\n",
      "The [0.4474771022796631, 0.24139578640460968]\n",
      ". [0.4531914293766022, 0.37865564227104187]\n",
      "Author [0.6994045376777649, 0.21164637804031372]\n",
      "Design [0.470569372177124, 0.4420590400695801]\n",
      "Peer [0.5016598105430603, 0.4427132308483124]\n",
      "August [0.6866803765296936, 0.2094256579875946]\n",
      "Example [0.5900185704231262, 0.24982959032058716]\n",
      ". [0.45078206062316895, 0.305014431476593]\n",
      "Flare [0.5807263851165771, 0.3257579803466797]\n",
      "Meyer [0.5315021276473999, 0.34316354990005493]\n",
      "The [0.5461774468421936, 0.27678924798965454]\n",
      "María [0.684122622013092, 0.19754169881343842]\n",
      "Doña [0.6525354981422424, 0.2555365562438965]\n",
      "Example [0.47716596722602844, 0.44130635261535645]\n",
      "User [0.5105963349342346, 0.42996522784233093]\n",
      "Members [0.6019677519798279, 0.2394462376832962]\n",
      "Case [0.4471585750579834, 0.41679760813713074]\n",
      "a [0.5666477680206299, 0.31538698077201843]\n",
      "a [0.7188751697540283, 0.19652952253818512]\n",
      "They [0.26619070768356323, 0.05200815945863724]\n",
      "Departments [0.1737535297870636, 0.16450652480125427]\n",
      "Darden [0.43281450867652893, 0.4227883517742157]\n",
      "Meyer [0.6577244997024536, 0.18264350295066833]\n",
      "Meyer [0.6392507553100586, 0.19803063571453094]\n",
      "​Matshepo​ [0.5376799702644348, 0.3136259913444519]\n",
      "User [0.6066980957984924, 0.2589069604873657]\n",
      "Madrid [0.419840544462204, 0.413331538438797]\n",
      "Name [0.8698998093605042, 0.10069821029901505]\n",
      ". [0.6097084879875183, 0.22082176804542542]\n",
      "our [0.48018932342529297, 0.3568463921546936]\n",
      "This [0.4007149636745453, 0.3536297082901001]\n",
      "By- [0.4989995062351227, 0.4009573757648468]\n",
      "Author [0.7631706595420837, 0.1624884009361267]\n",
      "The [0.40176922082901, 0.38337087631225586]\n",
      "Author [0.8513984084129333, 0.09778954833745956]\n",
      "Thinking [0.31220370531082153, 0.2932882606983185]\n",
      "Reflection [0.5029016733169556, 0.3886123299598694]\n",
      "Reflection [0.442982017993927, 0.42935287952423096]\n",
      "Instructor [0.7229461073875427, 0.2257147878408432]\n",
      "Peer [0.6024432182312012, 0.29823100566864014]\n",
      "Students [0.482428640127182, 0.45675426721572876]\n",
      "The [0.4713159203529358, 0.3368343114852905]\n",
      "they [0.6938892006874084, 0.24168246984481812]\n",
      "\n",
      "\n",
      " [0.4459511935710907, 0.2501559555530548]\n",
      "Name [0.8056025505065918, 0.08968271315097809]\n",
      "She [0.4958025813102722, 0.3861314356327057]\n",
      "Sally [0.6056292653083801, 0.26252084970474243]\n",
      "Herself [0.4389888346195221, 0.3754870891571045]\n",
      "a [0.8336273431777954, 0.11640046536922455]\n",
      "She [0.4952116012573242, 0.35948505997657776]\n",
      "She [0.5241537690162659, 0.28275972604751587]\n",
      "One [0.5002947449684143, 0.40515103936195374]\n"
     ]
    }
   ],
   "source": [
    "for p, gt in zip(neg_with_ctx, negatives):\n",
    "    if p[0] > p[1]:\n",
    "        print(gt, p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
