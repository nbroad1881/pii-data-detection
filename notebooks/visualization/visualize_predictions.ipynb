{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this is to make it easier to see how the model makes predictions. This is also to double-check that optimal post-processing is done and no bugs are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer\n",
    "import pickle\n",
    "\n",
    "d = Path(\"/drive2/kaggle/pii-dd/piidd/inference/outputs/d3l\")\n",
    "model_path = \"/drive2/kaggle/pii-dd/piidd/training/basic/outputs/d3l_1e-5_f_ld0.1_msd/checkpoint-1750\"\n",
    "\n",
    "np_preds = np.load(str(d / \"preds.npy\"))\n",
    "eval_ds = Dataset.from_parquet(str(d / \"ds.pq\"))\n",
    "tokenized_ds = Dataset.from_parquet(str(d / \"tds.pq\"))\n",
    "char_preds = pickle.load(open(d / \"char_preds.pkl\", \"rb\"))\n",
    "\n",
    "eidx2tidxs = {}\n",
    "\n",
    "for i, x in enumerate(tokenized_ds[\"idx\"]):\n",
    "    if x not in eidx2tidxs:\n",
    "        eidx2tidxs[x] = []\n",
    "    \n",
    "    eidx2tidxs[x].append(i)\n",
    "\n",
    "didx2eidx = {d: i for i, d in enumerate(eval_ds[\"document\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "id2label = json.load(open(str(Path(model_path) / \"config.json\")))[\"id2label\"]\n",
    "\n",
    "def make_table_header(id2label):\n",
    "    html = \"\"\n",
    "    for i in range(len(id2label)):\n",
    "        html += f\"<th>{id2label[str(i)]}</th>\"\n",
    "\n",
    "    return html\n",
    "\n",
    "\n",
    "def generate_html_table(tokens, scores):    \n",
    "    # Start of the HTML string\n",
    "    html = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <style>\n",
    "        .highest {\n",
    "            background-color: #66ff33;\n",
    "        }\n",
    "        .medium {\n",
    "            background-color: #ccffff;\n",
    "        }\n",
    "        .low {\n",
    "            background-color: #ff99ff;\n",
    "        }\n",
    "        .tiny {\n",
    "            background-color: #ffb3b3;\n",
    "        }\n",
    "        .zero {\n",
    "            background-color: rgba(0,0,0,0.1);\n",
    "        }\n",
    "        table {\n",
    "            border-collapse: collapse;\n",
    "            width: 100%;\n",
    "        }\n",
    "        th, td {\n",
    "            text-align: center;\n",
    "            padding: 0px;\n",
    "            border: 1px solid black;\n",
    "        }\n",
    "        th {\n",
    "            font-size: 12px;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "    <th>Token</th>\n",
    "    \"\"\" + make_table_header(id2label) + \"\"\"\n",
    "    </tr>\"\"\"\n",
    "    \n",
    "    for token, score in zip(tokens, scores):\n",
    "        row = f\"\\n    <tr>\\n        <td>{token}</td>\"\n",
    "        for s in score:\n",
    "            # Apply high-score class based on the score value\n",
    "            class_name = \"zero\"\n",
    "            if s > 0.9:\n",
    "                class_name = \"highest\"\n",
    "            elif s > 0.7:\n",
    "                class_name = \"medium\"\n",
    "            elif s > 0.5:\n",
    "                class_name = \"low\"\n",
    "            elif s > 0.3:\n",
    "                class_name = \"tiny\"\n",
    "            row += f\"\\n        <td class='{class_name}'>{s:.2f}</td>\"\n",
    "        row += \"\\n    </tr>\"\n",
    "        html += row\n",
    "    \n",
    "    # End of the HTML string\n",
    "    html += \"\"\"\n",
    "</table>\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/nicholas/miniconda3/lib/python3.10/site-packages/gradio/queueing.py\", line 495, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "  File \"/home/nicholas/miniconda3/lib/python3.10/site-packages/gradio/route_utils.py\", line 231, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/home/nicholas/miniconda3/lib/python3.10/site-packages/gradio/blocks.py\", line 1591, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/home/nicholas/miniconda3/lib/python3.10/site-packages/gradio/blocks.py\", line 1176, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/home/nicholas/miniconda3/lib/python3.10/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/home/nicholas/miniconda3/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/home/nicholas/miniconda3/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/home/nicholas/miniconda3/lib/python3.10/site-packages/gradio/utils.py\", line 678, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_52675/606152895.py\", line 28, in load_token_preds\n",
      "    idx = didx2eidx[doc_id]\n",
      "KeyError: 9493\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import random\n",
    "from scipy.special import softmax\n",
    "\n",
    "\n",
    "def load_preds(doc_id, do_softmax, char=False):\n",
    "    idx = didx2eidx[doc_id]\n",
    "\n",
    "    if char:\n",
    "        preds = char_preds[idx]\n",
    "    else:\n",
    "        preds = [np_preds[x] for x in eidx2tidxs[idx]]\n",
    "\n",
    "    if do_softmax:\n",
    "        preds = [softmax(x, -1) for x in preds]\n",
    "\n",
    "    return preds\n",
    "\n",
    "\n",
    "def get_random_id():\n",
    "\n",
    "    doc_id = random.choice(list(didx2eidx.keys()))\n",
    "\n",
    "    return doc_id\n",
    "\n",
    "\n",
    "def load_token_preds(doc_id, chunk, do_softmax):\n",
    "    idx = didx2eidx[doc_id]\n",
    "\n",
    "    preds = load_preds(doc_id, do_softmax)\n",
    "\n",
    "    offset_mapping = [tokenized_ds[x][\"offset_mapping\"] for x in eidx2tidxs[idx]]\n",
    "    text = eval_ds[idx][\"full_text\"]\n",
    "\n",
    "    return show_scores(preds[chunk], offset_mapping[chunk], text)\n",
    "\n",
    "\n",
    "def load_char_preds(doc_id, chunk, do_softmax):\n",
    "    idx = didx2eidx[doc_id]\n",
    "\n",
    "    preds = load_preds(doc_id, do_softmax, char=True)\n",
    "\n",
    "    text = eval_ds[idx][\"full_text\"]\n",
    "\n",
    "    return show_scores(preds, text, text, chars=True)\n",
    "\n",
    "\n",
    "\n",
    "def show_scores(preds, offset_mapping, text, chars=False):\n",
    "    if chars:\n",
    "        tokens = list(text)\n",
    "    else:\n",
    "        tokens = [text[m[0]:m[1]] for m in offset_mapping]\n",
    "\n",
    "    try:\n",
    "        html = generate_html_table(tokens, preds)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "\n",
    "    return html\n",
    "\n",
    "\n",
    "with gr.Blocks(css=\"\"\".gradio-container {margin: 0 !important; max-width: 4000px};\"\"\") as demo:\n",
    "\n",
    "    rnd = gr.Button(\"Random\")\n",
    "    do_softmax = gr.Checkbox(False, label=\"Softmax\")\n",
    "    doc_id = gr.Slider(0, 1000000, 0, label=\"Doc ID\")\n",
    "    chunk = gr.Slider(0, 10, step=1)\n",
    "\n",
    "\n",
    "    with gr.Tab(\"Model token preds\"):\n",
    "        refresh_token = gr.Button(\"Refresh\")\n",
    "        html_token = gr.HTML()\n",
    "    with gr.Tab(\"Char preds\"):\n",
    "        refresh_char = gr.Button(\"Refresh\")\n",
    "        html_char = gr.HTML()\n",
    "\n",
    "\n",
    "    rnd.click(fn=get_random_id, outputs=doc_id)\n",
    "\n",
    "    refresh_token.click(fn=load_token_preds, inputs=[doc_id, chunk, do_softmax], outputs=html_token)\n",
    "    refresh_char.click(fn=load_char_preds, inputs=[doc_id, chunk, do_softmax], outputs=html_char)\n",
    "\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
